**从某种意义上来说，本书的目的就是了解，当在系统中执行程序时，系统会发生什么，以及为什么会这样**

---
# 1.1 信息就是位 + 上下文
系统中所有的信息一包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。

# 1.2 程序被其他程序翻译成不同的格式
程序的生命周期通常是从一个高级语言开始的，以便人能读懂。但是，为了能在系统上运行程序，需要机器能读懂，于是每条语句都必须被其他程序转化为一系列低级的**机器语言**指令。然后这些指令按照一种称为**可执行文件目标程序**的格式打包好，并以二进制磁盘文件的形式存放起来。目标程序也称为**可执行目标文件**。（就比如编译cpp文件会产生一个exe文件，运行是运行这个exe文件）
这个翻译过程可分为四个阶段完成，如图![[../../attachments/Pasted image 20250825161218.png]]执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统。
 - 预处理阶段。根据以字符#开头的命令，修改原始的C程序。比如 `hello.c` 中第1行 `#include<stdio.h>` 命令告诉预处理器读取系统头文件 `stdio.h`的内容，并把它直接插入程序文本中。结果就得到了另一个C程序。
 - 编译阶段。将上一个阶段的文本文件翻译成汇编语言程序的文本文件，每一条语句都以一种文本格式描述一条低级机器语言指令。
 - 汇编阶段。将上一阶段的文本文件翻译成机器语言指令，并把这些指令打包成一种叫做**可重定位目标程序**的格式，并将结果保存在目标文件中（该文件是个二进制文件）
 - 链接阶段。链接其他需要使用的单独的预编译好了的目标文件，从而得到可执行文件，可以被加载到内存中，由系统执行。

# 1.3 了解编译系统如何工作是大有益处的
益处：优化程序性能；理解链接时出现的错误；避免安全漏洞

# 1.4 处理器读并解释储存在内存中的指令
在 Unix 系统上运行可执行文件，是通过 Shell 来运行。（[[../../Shell/The Shell|The Shell]]）

## 1.4.1 系统的硬件组成
![[../../attachments/Pasted image 20250825163037.png]]
### 1. 总线
Bus -- 携带信息字节并负责在各个部件间传递
### 2. I/O 设备
是系统与外部世界的联系通道。每个 I/O 设备都通过一个控制器与适配器与 I/O 总线相连。控制器与适配器的区别主要在于它们的封装方式：控制器是 I/O 设备本身或者系统的主板上的芯片组，而适配器则是一块插在主板插槽上的卡
### 3. 主存
是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存取存储器(DRAM)芯片组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的
### 4. 处理器
- 中央处理单元(CPU)，简称处理器，是解释（或执行）存储在主存中指令的引擎
- 处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器(PC)
- 在任何时刻，PC 都指向主存中的某条机器语言指令（即含有该条指令的**地址**）。从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一条指令
- 处理器看上去是按照一个非常简单的指令执行模型来操作的，这个模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行，而执行一条指令包含执行一系列的步骤。处理器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新 PC ，使其指向下一条指令，而这条指令并不一定和在内存中刚刚执行的指令相邻
- 这样的简单操作并不多，它们围绕着主存、寄存器文件和算术/逻辑单元(ALU)进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。ALU 计算新的数据和地址值
- 处理器看上去是它的指令集架构的简单实现，但是实际上现代处理器使用了非常复杂的机制来加速程序的执行。因此，我们将处理器的指令集架构和处理器的微体系结构区分开来：指令集架构描述的是每条机器代码指令的效果；而微体系结构描述的是处理器实际上是如何实现的

## 1.4.2 运行程序
![[../../attachments/Pasted image 20250825165719.png]]![[../../attachments/Pasted image 20250825165744.png]]![[../../attachments/Pasted image 20250825165757.png]]

# 1.5 高速缓存至关重要
根据 1.4.2 的过程，我们了解到系统花费了大量的时间把信息从一个地方挪到另一个地方。而较大的存储设备要比较小的存储设备运行得慢，而快速设备的造假远高于同类的低速设备。类似地，一个典型的寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。更麻烦的是，随着半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。
针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为**高速缓存存储器**（cache memory，简称 cache 或高速缓存），作为暂时的集结区域，存放处理器近期可能会需要的信息。

## 1.6 存储设备形成层次结构
每个计算机系统中的存储设备都被组织成了一个**存储器层次结构**，如图![[../../attachments/Pasted image 20250825171303.png]]该层次结构的主要思想是上一层的存储器作为第一层的高速缓存。

## 1.7 操作系统管理硬件
当运行程序时，并没有直接访问硬件设备，而是依靠**操作系统**提供的服务，我们可以把操作系统看成是应用程序和硬件之间插入的一层软件，而所有的应用程序对硬件的尝试都必须通过操作系统。![[../../attachments/Pasted image 20250825171741.png]]
操作系统有两个基本功能：(1)防止硬件被失控的应用程序滥用；(2)向应用程序
提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。
### 1.7.1 进程
**进程**是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而**并发运行**，则是说一个进程的指令和个进程的指令是 *交错执行* 的。在大多数系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论是在单核还是多核系统中，一个CPU看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制称为**上下文切换**。
操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是**上下文**，包括许多信息，比如PC和寄存器文件的当前值，以及主存的内容。在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。新进程就会从它上次停止的地方开始。![[../../attachments/Pasted image 20250825172628.png]]
从一个进程到另一个进程的转换是由操作系统**内核**(kernel)管理的。内核是操作系统代码 *常驻主存* 的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的**系统调用**(system call)指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。

### 1.7.2 线程
在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。当有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法。

### 1.7.3 虚拟内存
虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为**虚拟地址空间**。![[../../attachments/Pasted image 20250825173037.png]]如图所示是 Linux 进程的虚拟地址空间，图中的地址是从下往上增大的。
在Linux中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。从最低的地址开始介绍：
 - 程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和C全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。
 - 堆。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被**指定了大小**，与此不同，当调用像malloc和free这样的C标准库函数时，堆可以在运行时**动态**地扩展和收缩。
 - 共享库。大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域。
 - 栈。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现**函数调用**。和堆一样，用户栈在程序执行期间可以**动态**地扩展和收缩。特别地，每次我们调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩。
 - 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，它们**必须调用内核来执行这些操作**。
虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互，包括对处理器生成的每个地址的硬件翻译。基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存。

### 1.7.4 文件
文件就是字节序列，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。系统中的所有输人输出都是通过使用一小组称为 Unix I/O 的系统函数调用读写文件来实现的。
文件这个简单而精致的概念是非常强大的，因为它向应用程序提供了一个统一的视图，来看待系统中可能含有的所有各式各样的 I/O 设备。

## 系统之间利用网络通信
如 1.7.4 所说，网络也可以看成是文件，当系统从主存复制一串字节到网络适配器时，数据流经过网络
到达另一台机器，而不是比如说到达本地磁盘驱动器。相似地，系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存。![[../../attachments/Pasted image 20250825193956.png]]

## 1.9 重要概念
### 1.9.1 Amdahl 定律
当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。若系统执行某应用程序**需要时间**为 $T_{old}$ 。假设系统某部分所需**执行时间**与该时间的比例为 $α$ ,而该部分**性能提升比例**为 $k$ 。即该部分**初始所需**时间为 $αT_{old}$ ，**现在所需**时间为 $(αT_{old})/k$ 。因此，总的**执行时间**应为$$T_{new} = (1-α)T_{old} + (αT_{old})/k = T_{old}[(1-α)+α/k]$$
由此。可以计算加速比 $S=T_{old}/T_{new}$为$$S = \frac{1}{(1-α)+α/k}$$
所以，要想显著加速整个系统，必须提升全系统中相当大的部分的速度。
有一个特殊情况是考虑 $k$ 趋向于 ∞ 时的效果，这时，我们可以取系统的某一部分将其加速到一个点，在这个点上，这部分花费的时间可以忽略不计，于是$$S_∞ = \frac{1}{1-α}$$
### 1.9.2 并发和并行
并发（concurrency）指一个同时具有多个活动的系统
并行（parallelism）指的是用并发来使一个系统运行得更快，并行可以在计算机系统的多个抽象层次上运用

在此，我们按照系统层次结构中由高到低的顺序强调三个层次
#### 1. 线程级并发
构建在进程这个抽象之上，我们能够设计出同时有多个程序执行的系统，这就导致了并发。使用线程，我们甚至能够在一个进程中执行多个控制流。
超线程，有时称为同时多线程，是一项允许一个 CPU 执行多个控制流的技术。它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份，比如执行浮点算术运算的单元。常规的处理器需要大约20000个时钟周期做不同线程间的转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。这使得CPU能够更好地利用它的处理资源。比如，假设一个线程必须等到某些数据被装载到高速缓存中，那CPU就可以继续去执行另一个线程。
多处理器的使用可以从两方面提它减少了在执行多个任务时模拟并发的需要。正如前面提到的，即使是只有一个用户使用的个人计算机也需要并发地执行多个活动。其次，它可以使应用程序运行得更快，当然，这必须要求程序是以多线程方式来书写的，这些线程可以并行地高效执行。
#### 2. 指令级并行
在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。
如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量处理器。
#### 3. 单指令、多数据并行
在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。
提供这些 SIMD 指令多是为了提高处理影像、声音和视频数据应用的执行速度。虽然有些编译器会试图从 C 程序中自动抽取 SIMD 并行性，但是更可靠的方法是用编译器支持的特殊的向量数据类型来写程序，比如 GCC 就支持向量数据类型。

### 计算机系统中抽象的重要性
抽象的使用是计算机科学中最为重要的概念之一。
在处理器里，指令集架构提供了对实际处理器硬件的抽象。使用这个抽象，机器代码程序表现得就好像运行在一个一次只执行一条指令的处理器上。底层的硬件远比抽象描述的要复杂精细，它并行地执行多条指令，但又总是与那个简单有序的模型保持一致。只要执行模型一样，不同的处理器实现也能执行同样的机器代码，而又提供不同的开销和性能。![[../../attachments/Pasted image 20250825211415.png]]
