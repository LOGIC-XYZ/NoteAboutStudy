写程序最主要的目的是使它在所有可能的情况下都正确工作，速度快但结果错误的程序毫无意义。同时，代码应清晰简洁、可读和易于维护，这不仅对自己更是其他人理解和维护十分友好。

在此基础上，很多情况下，也对程序的性能有要求：
- 对实时任务（视频处理、网络包处理）或长时间计算任务（数日/数周运行的计算）来说，运行速度很重要；
- 小幅度性能提升也可能产生重大影响；
本章将探讨如何使用几种不同类型的程序优化技术，使程序运行得更快。

编写高效程序需要做到以下几点：
- 选择适当的算法与数据结构：
	- 基础且最重要的优化手段；
	- 决定了程序的整体效率上限；
- 编写易于编译器优化以转换成高效可执行代码的源代码：
	- 需要理解编译器的优化能力与限制；
	- 小的源代码写法差异可能导致编译器生成性能大不相同的机器码；
	- 有些编程语言比其他语言容易优化；
- 针对处理运算量特别大的计算，利用并行性，将计算任务拆分在多核或多处理器上并行计算（将在 12 章中讲述，但是每个线程仍需高校执行）；

在程序开发和优化的过程中，必须考虑代码使用的方式，以及影响它的关键因素。通常，程序员必须在实现和维护程序的简单性与它的运行速度之间做出权衡。一个挑战就是尽管做了大量的优化，但还是要维护代码一定程度的简洁和可读性。

关于提高代码性能，理想的情况是，编译器能够接受所编写的任何代码，并产生尽可能高效的、具有指定行为的机器级程序。为此，现代编译器采用了复杂的分析和优化形式，而且变得越来越好。然而，即使是最好的编译器也受到 **妨碍优化的因素（optimization blocker）** 的阻碍，妨碍优化的因素就是程序行为中那些严重依赖于执行环境的方面。程序员必须编写容易优化的代码，以帮助编译器。

**程序优化**：
1. **消除不必要的工作**，让代码尽可能有效地执行所期望的任务 -- 减少函数调用、条件判断和内存引用，这些优化不依赖于目标机器的任何具体属性；
2. **理解目标机器与处理器**
	- 知道了处理器指令时序和执行特性，有助于选择最有实现（如乘法 vs 移位加法组合）；
	- 现代计算机用复杂的技术来处理机器级程序，并行地执行许多指令，执行顺序还可能不同于它们在程序中出现的顺序；
3. **利用指令级并行**，降低数据依赖，增加可并行执行的指令数量；
4. **分析和测量性能**
	- 使用 **代码剖析程序** 测量程序各个部分性能的工具，找出性能瓶颈；
	- 研究程序的汇编代码表示是理解编译器以及产生的代码会如何运行的最有效手段之一，然后再据此修改源代码：
		- 从汇编代码开始，可以预测什么操作会并行执行，以及它们会如何使用处理器资源；
		- 常常通过确认 **关键路径(critical path)** 来决定执行一个循环所需要的时间（或者说，至少是一个时间下界），所谓关键路径是在循环的反复执行过程中形成的数据相关链；
5. **反复试验与源码调整**
	- 通过多次修改源代码，调整编译器生成的机器码性能；
	- 保持代码可读性与可移植性，同时提高效率；
	- 相比直接写汇编，优化源代码能兼顾可读性、模块性和可移植性；

---
# 5.1 优化编译器的能力和局限性
编译器的任务不仅是把源代码翻译成机器码，还要**自动优化程序的性能**，比如：
- 让程序运行更快；
- 让程序占用更少的寄存器或内存；
- 减少分支跳转、缓存缺失等开销。
但这些优化**必须在不改变程序语义的前提下**进行，也就是说：
> 编译器“能优化的部分”，都是在 **逻辑完全等价** 的情况下。

而编译器能自动执行一些常规优化，尤其是对 **循环、常量、局部变量** 等部分，现代编译器（如 GCC、Clang、MSVC）都可以做到这些：

| 优化类型                              | 示例                               | 效果           |
| --------------------------------- | -------------------------------- | ------------ |
| **常量传播** (Constant Propagation)   | `int x = 3 * 5;` → `int x = 15;` | 消除不必要的运算     |
| **强度削弱** (Strength Reduction)     | `x * 8` → `x << 3`               | 用更快的操作代替慢操作  |
| **公共子表达式消除**                      | `a*b + a*b` → `t = a*b; t + t`   | 避免重复计算       |
| **死代码消除** (Dead Code Elimination) | 移除对结果无影响的代码                      | 减少无用执行       |
| **循环展开** (Loop Unrolling)         | 把循环多次迭代合并执行                      | 减少分支、提高指令并行性 |
| **寄存器分配优化**                       | 频繁使用的变量放寄存器                      | 减少内存访问       |
| **指令调度** (Instruction Scheduling) | 调整指令顺序避免流水线停顿                    | 提升 ILP 并行度   |

但是，编译器不能 “理解” 程序的语义意图，它的优化也有诸多限制：
1. **指针与别名分析的限制**：两个指针可能指向同一个内存位置的情况称为 **内存别名使用（memory aliasing）**。此时，就必须假设什么情况都有可能，这就限制了可能的优化策略；
2. **函数调用的副作用**：编译器无法知道被调用的函数是否修改了全局变量或指针所指内容，此时，编译器会假设最糟的情况，并保持所有的函数调用不变；
3. **跨模块、跨语言边界的优化难度**：不同的文件或库之间，编译器往往缺乏全局视野
	- 编译单元之间的优化（如函数内联）受限；
	- 链接时优化（LTO）虽可改善，但仍然有限。
4. **算法层面的优化无法自动完成**：编译器无法理解 “意图”，只能在 **实现层面微调**；

编译器的优化也分等级，一下以 GCC 为例：

| 优化等级  | 命令行选项   | 说明                |
| ----- | ------- | ----------------- |
| 无优化   | `-O0`   | 快速编译，便于调试         |
| 基础优化  | `-O1`   | 启用安全的局部优化         |
| 较强优化  | `-O2`   | 启用更多优化（寄存器、循环展开等） |
| 激进优化  | `-O3`   | 强化向量化、内联、ILP 等    |
| 链接时优化 | `-flto` | 跨文件全局优化           |

# 5.2 表示程序性能
引入度量标准 - **每元素的周期数(Cycles Per Element,CPE)**，作为一种表示程序性能并指导如何改进代码。CPE 这种度量标准使能够在更细节的级别上理解迭代程序的循环性能。这样的度量标准对执行重复计算的程序来说是很适当的，例如处理图像中的像素，或是计算矩阵乘积中的元素。

> “程序运行总时间 ≈ 固定开销 + 每元素花的时间 × 元素数”
> 当 **元素数** 足够大时，固定开销可以忽略，只需比较 CPE 大小。

更愿意用每个元素的周期数而不是每次循环的周期数来度量，这是因为**程序的根本目标是处理完 n 个数据需要多少时间**，如果用 “每次循环的周期数” 去比较，不同优化会改变循环次数（如循环展开、向量化等），这会导致**循环层面的指标不再可比**；  
因此，更合理的做法是用 **每个数据元素的平均周期数（CPE）** 来衡量性能，  
这样无论循环结构怎么变化，都能反映真实的“单位数据处理效率”。

# 5.3 程序示例
为了说明一个抽象的程序是如何被系统地转换成更有效的代码的，该节将使用一个基于图 5-3 所示向量数据结构的运行示例。

![[NoteAboutStudy/attachments/Pasted image 20251019223343.png]]

向量由两个内存块表示：头部和数据数组。头部是一个声明如下的结构：
```c
/*Create abstract data type for vector */
typedef struct{
	long len;
	data_t *data;
}vec_rec,*vec_ptr;
```

这个声明用 `data_t` 来表示基本元素的数据类型。在测试中，度量代码对于整数( C 语言的 `int` 和 `long`)和浮点数( C 语言的 `float` 和 `double`)数据的性能。为此，会分别为不同的类型声明编译和运行程序，就像这个例子对数据类型 `long`一样：`typedef long data_t;`，还会分配一个包含 `len` 个 `data_t` 类型对象的数组，来存放实际的向量元素。

其实这节就是根据程序示例来讲解优化程序，具体细节还是看书吧，主要是以下几点：
- CPE 是核心指标：衡量单位数据的代价；
- 理解**内存访问 vs 计算指令**谁是瓶颈；
- 利用**循环展开和多累加**打破依赖链，依赖链会限制流水线效率；
- 知道编译器能做什么、不能做什么，同时，编译器优化有限，手动展开与多累加更有效；
- 性能优化要基于**分析与实验**，不是猜测；

# 5.4 消除循环的低效率
把不会随循环变化的计算，移出循环体执行，从而避免重复执行。 -- 这类优化被称为 **代码移动(code motion)**。

例如：
- 常量表达式；
- 与循环无关的函数调用；
- 不依赖循环变量的中间结果。
这样可以显著减少重复计算，提高指令吞吐。

 ⚠️ 但编译器未必能自动做到：
- 编译器无法判断一个函数是否有 **副作用（side effect）**；
- 比如函数内部是否修改了全局变量；
- 所以它会 “保守地” 认为可能有副作用，不轻易移动调用。
因此，**程序员往往必须显式地帮助编译器完成代码移动。**

同时，循环低效率中也有个常见的问题 --  **渐近低效率**。
何为渐进低效率？在性能优化中，渐近效率指的是算法在输入规模增大时的增长趋势 -- 也就是时间复杂度或空间复杂度的变化规律。在编程中，某些代码片段在小规模数据下可能表现正常，但由于包含了重复或不必要的操作，随着输入规模增加，性能恶化速度远超预期。

# 5.5 减少过程调用
过程调用会带来开销，而且妨碍大多数形式的程序优化。

但是简单地消除函数调用，并一定能显著提升性能，因为程序性能往往受制于更深层的瓶颈，而不是表面上的函数调用开销。
- **函数调用开销相对很小**  
    在现代处理器中，函数调用的开销往往只占几条指令的时间，而循环内可能有几十上百条其他计算或内存操作，这些操作才是主要的瓶颈。
- **真正的瓶颈在于内存访问或流水线阻塞**  
    去掉函数调用不会改变这些核心问题。 
- **编译器优化可能自动内联函数**  
    如果编译器足够聪明，它会直接展开，那 “函数调用开销” 就消失了。人为修改代码反而可能破坏其他优化或缓存局部性。

# 5.6 消除不必要的内存引用
有的循环中可能会有多余内存读写，比如说，每次循环迭代都从内存中读取累积变量进行计算，再把结果写回内存，这样就会导致 **每次迭代都会有多余的内存访问，而这些访问的开销远大于计算本身。**

对于这种情况。通过引入一个局部变量，在寄存器中累积结果，**只在循环结束后再写回内存**。
- 循环内只需读取数组数据一次；
- 累积值保存在寄存器中。
这种方式将每次迭代的内存操作减少为**一次读**。

而编译器不能自动完成这个的原因在于编译器无法确定用户意图，因此只能采取**保守策略**，维持每次迭代的读写操作。（内存别名的问题）

# 5.7 理解现代处理器
到目前为止，所运用的优化都不依赖于目标机器的任何特性。这些优化只是简单地降低了过程调用的开销，以及消除了一些重大的 “妨碍优化的因素” ，这些因素会给优化编译器造成困难。

随着试图进一步提高性能，必须考虑利用处理器微体系结构的优化，也就是处理器用来执行指令的底层系统设计。要想充分提高性能，需要仔细分析程序，同时代码的生成也要针对目标处理器进行调整。

尽管如此，还是能够运用一些基本的优化，在很大一类处理器上产生整体的性能提高。在该节讲述的详细性能结果，对其他机器不一定有同样的效果，但是操作和优化的通用原则对各种各样的机器都适用。

虽然现代微处理器的详细设计超出了本书讲授的范围，对这些微处理器运行的原则有一般性的了解就足够能够理解它们如何实现指令级并行。两种下界描述了程序的最大性能。当一系列操作必须按照严格顺序执行时，就会遇到 **延迟界限（latency bound）**，因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。**吞吐量界限（throughput bound）** 刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。

---
## 5.7.1 整体操作
![[NoteAboutStudy/attachments/Pasted image 20251020213734.png]]

图 5-11 是现代微处理器的一个非常简单化的示意图。之前假想的处理器设计是不太严格地基于近期的 Intel 处理器的结构（和现在的比更不太严格了）。

这些处理器在工业界称为 **超标量（superscalar）**，意思是它可以在每个时钟周期执行多个操作，而且是 **乱序的（out-of-order）**，意思就是指令执行的顺序不一定要与它们在机器级程序中的顺序一致。

整个设计有两个主要部分：**指令控制单元（Instruction Control Unit，ICU）** 和 **执行单元（ExecutionUnit，EU）**。前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作；而后者执行这些操作。

和第 4 章中研究过的 **按序（in-order）** 流水线相比，乱序处理器需要更大、更复杂的硬件，但是它们能更好地达到更高的指令级并行度。

---
### 取指阶段
ICU 从 **指令高速缓存（instruction cache）** 中读取指令（指令高速缓存是一个特殊的高速存储器，它包含最近访问的指令）。为了避免停顿，通常，ICU 会在当前正在执行的指令很早之前取指，这样它才有足够的时间对指令译码，并把操作发送到 EU。

不过，一个问题是当程序遇到分支时，程序有两个可能的前进方向：
- 一种可能会选择分支，控制被传递到分支目标。
- 另一种可能是，不选择分支，控制被传递到指令序列的下一条指令。
现代处理器采用了一种称为 **分支预测（branch prediction）** 的技术，处理器会猜测是否会选择分支，同时还预测分支的目标地址。并利用 **投机执行（speculativeexecution）** 的技术，处理器会开始取出位于它预测的分支会跳到的地方的指令，并对指令译码，甚至在它确定分支预测是否正确之前就开始执行这些操作。如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并开始取出和执行另一个方向上的指令。

在处理器的结构图中，这些分支预测与取指逻辑通常由 **取指控制（fetch control）** 模块完成，用于决定下一步应从哪个地址取指令。

### 译码阶段
**指令译码** 逻辑接收实际的程序指令，并将它们转换成一组基本操作（有时称为 **微操作**）。每个这样的操作都完成某个简单的计算任务。而对于具有复杂指令的机器，比如 x86 处理器，一条指令可以被译码成多个操作。

关于指令如何被译码成操作序列的细节，不同的机器都会不同，这个信息可谓是高度机密。幸运的是，不需要知道某台机器实现的底层细节，也能优化自己的程序。

### 执行阶段
#### 操作执行
EU 接收来自取指单元的操作。通常，每个时钟周期会接收多个操作。这些操作会被分派到一组功能单元中，它们会执行实际的操作。这些功能单元专门用来处理不同类型的操作。

读写内存是由加载和存储单元实现的。加载单元处理从内存读数据到处理器的操作。这个单元有一个加法器来完成地址计算。类似，存储单元处理从处理器写数据到内存的操作。它也有一个加法器来完成地址计算。如图中所示，加载和存储单元通过 **数据高速缓存（data cache）** 来访问内存（数据高速缓存是一个高速存储器，存放着最近访问的数据值）

#### 结果暂存与数据转发
使用投机执行技术对操作求值，但是最终结果不会存放在程序寄存器或数据内存中，直到处理器能确定应该实际执行这些指令。分支操作被送到 EU，不是确定分支该往哪里去，而是确定分支预测是否正确。如果预测错误，EU 会丢弃分支点之后计算出来的结果。它还会发信号给分支单元，说预测是错误的，并指出正确的分支目的。在这种情况中，分支单元开始在新的位置取指。如在 3.6.6 节中看到的，这样的预测错误会导致很大的性能开销。在可以取出新指令、译码和发送到执行单元之前，要花费一点时间。

图 5-11 说明不同的功能单元被设计来执行不同的操作。那些标记为执行 “算术运算” 的单元通常是专门用来执行整数和浮点数操作的不同组合。随着时间的推移，在单个微处理器芯片上能够集成的晶体管数量越来越多，后续的微处理器型号都增加了功能单元的数量以及每个单元能执行的操作组合，还提升了每个单元的性能。由于不同程序间所要求的操作变化很大，因此，算术运算单元被特意设计成能够执行各种不同的操作。比如，有些程序也许会涉及整数操作，而其他则要求许多浮点操作。如果一个功能单元专门执行整数操作，而另一个只能执行浮点操作，那么，当程序主要使用某一类运算时，其他单元将无法被有效利用，从而降低整体的硬件资源利用率。

#### 指令退役与寄存器重命名
在 ICU 中，**退役单元（retirementunit）** 记录正在进行的处理，并确保它遵守机器级程序的顺序语义。图 5-11 中展示了一个寄存器文件，它包含整数、浮点数和最近的 SSE 和 AVX 寄存器，是退役单元的一部分，因为退役单元控制这些寄存器的更新。指令译码时，关于指令的信息被放置在一个先进先出的队列中。这个信息会一直保持在队列中，直到发生以下两个结果中的一个。
- 首先，一旦一条指令的操作完成了，而且所有引起这条指令的分支点也都被确认为预测正确，那么这条指令就可以 **退役（retired）** 了，所有对程序寄存器的更新都可以被实际执行了。
- 另一方面，如果引起该指令的某个分支点预测错误，这条指令会被 **清空（flushed）**，丢弃所有计算出来的结果。通过这种方法，预测错误就不会改变程序的状态了。
正如已经描述的那样，任何对程序寄存器的更新都只会在指令退役时才会发生，只有在处理器能够确信导致这条指令的所有分支都预测正确了，才会这样做。为了加速一条指令到另一条指令的结果的传送，许多此类信息是在执行单元之间交换的，即图中的 “操作结果”。如图中的箭头所示，执行单元可以直接将结果发送给彼此。这是4.5.5节中简单处理器设计中采用的数据转发技术的更复杂精细版本。

而控制操作数在执行单元间传送的最常见的机制称为 **寄存器重命名（register renaming）**:
1. 当一条更新寄存器 `r` 的指令译码时，产生标记 `t`，得到一个指向该操作结果的唯一的标识符。
2. 条目 `(r，t)` 被加入到一张表中，该表维护着每个程序寄存器 `r` 与会更新该寄存器的操作的标记 `t` 之间的关联。
3. 当随后以寄存器 `r` 作为操作数的指令译码时，发送到执行单元的操作会包含 `t` 作为操作数源的值。
4. 当某个执行单元完成第一个操作时，会生成一个结果 `(v，t)`，指明标记为 `t` 的操作产生值。
5. 所有等待 `t` 作为源的操作都能使用作为源值，这就是一种形式的数据转发。
通过这种机制，值可以从一个操作直接转发到另一个操作，而不是写到寄存器文件再读出来，使得第二个操作能够在第一个操作完成后尽快开始。

重命名表只包含关于有未进行写操作的寄存器条目。当一条被译码的指令需要寄存器 `r`，而又没有标记与这个寄存器相关联，那么可以直接从寄存器文件中获取这个操作数。

有了寄存器重命名，即使只有在处理器确定了分支结果之后才能更新寄存器，也可以预测着执行操作的整个序列。

## 5.7.2 功能单元的性能
![[NoteAboutStudy/attachments/Pasted image 20251022221245.png]]
如图 5-12 提供了 `Intel Core i7 Haswell` 参考机的一些算术运算的性能，有的是测量出来的，有的是引用 `Intel` 的文献。这些时间对于其他处理器来说也是具有代表性的。每个运算都是由以下这些数值来刻画的：
- **延迟（latency）**，它表示完成运算所需要的总时间；
- **发射时间（issue time）**，它表示两个连续的同类型的运算之间需要的最小时钟周期数；
- **容量（capacity）**，它表示能够执行该运算的功能单元的数量。

可以看到
- 从整数运算到浮点运算，延迟是增加的；
- 加法和乘法运算的发射时间都为 1，意思是说在每个时钟周期，处理器都可以开始一条新的这样的运算 -- 这种很短的发射时间是通过使用流水线实现的。流水线化的功能单元实现为一系列的 **阶段（stage）**，每个阶段完成一部分的运算。

例如，一个典型的浮点加法器包含三个阶段（所以有三个周期的延迟）：一个阶段处理指数值，一个阶段将小数相加，而另一个阶段对结果进行舍入。

算术运算可以连续地通过各个阶段，而不用等待一个操作完成后再开始下一个。只有当要执行的运算是连续的、逻辑上独立的时候，才能利用这种功能。

发射时间为 1 的功能单元被称为 **完全流水线化的（fully pipelined）**：每个时钟周期可以开始一个新的运算。出现容量大于 1 的运算是由于有多个功能单元，就如前面所述的参考机一样。