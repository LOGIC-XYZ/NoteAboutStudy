写程序最主要的目的是使它在所有可能的情况下都正确工作，速度快但结果错误的程序毫无意义。同时，代码应清晰简洁、可读和易于维护，这不仅对自己更是其他人理解和维护十分友好。

在此基础上，很多情况下，也对程序的性能有要求：
- 对实时任务（视频处理、网络包处理）或长时间计算任务（数日/数周运行的计算）来说，运行速度很重要；
- 小幅度性能提升也可能产生重大影响；
本章将探讨如何使用几种不同类型的程序优化技术，使程序运行得更快。

编写高效程序需要做到以下几点：
- 选择适当的算法与数据结构：
	- 基础且最重要的优化手段；
	- 决定了程序的整体效率上限；
- 编写易于编译器优化以转换成高效可执行代码的源代码：
	- 需要理解编译器的优化能力与限制；
	- 小的源代码写法差异可能导致编译器生成性能大不相同的机器码；
	- 有些编程语言比其他语言容易优化；
- 针对处理运算量特别大的计算，利用并行性，将计算任务拆分在多核或多处理器上并行计算（将在 12 章中讲述，但是每个线程仍需高校执行）；

在程序开发和优化的过程中，必须考虑代码使用的方式，以及影响它的关键因素。通常，程序员必须在实现和维护程序的简单性与它的运行速度之间做出权衡。一个挑战就是尽管做了大量的优化，但还是要维护代码一定程度的简洁和可读性。

关于提高代码性能，理想的情况是，编译器能够接受所编写的任何代码，并产生尽可能高效的、具有指定行为的机器级程序。为此，现代编译器采用了复杂的分析和优化形式，而且变得越来越好。然而，即使是最好的编译器也受到 **妨碍优化的因素（optimization blocker）** 的阻碍，妨碍优化的因素就是程序行为中那些严重依赖于执行环境的方面。程序员必须编写容易优化的代码，以帮助编译器。

**程序优化**：
1. **消除不必要的工作**，让代码尽可能有效地执行所期望的任务 -- 减少函数调用、条件判断和内存引用，这些优化不依赖于目标机器的任何具体属性；
2. **理解目标机器与处理器**
	- 知道了处理器指令时序和执行特性，有助于选择最有实现（如乘法 vs 移位加法组合）；
	- 现代计算机用复杂的技术来处理机器级程序，并行地执行许多指令，执行顺序还可能不同于它们在程序中出现的顺序；
3. **利用指令级并行**，降低数据依赖，增加可并行执行的指令数量；
4. **分析和测量性能**
	- 使用 **代码剖析程序** 测量程序各个部分性能的工具，找出性能瓶颈；
	- 研究程序的汇编代码表示是理解编译器以及产生的代码会如何运行的最有效手段之一，然后再据此修改源代码：
		- 从汇编代码开始，可以预测什么操作会并行执行，以及它们会如何使用处理器资源；
		- 常常通过确认 **关键路径(critical path)** 来决定执行一个循环所需要的时间（或者说，至少是一个时间下界），所谓关键路径是在循环的反复执行过程中形成的数据相关链；
5. **反复试验与源码调整**
	- 通过多次修改源代码，调整编译器生成的机器码性能；
	- 保持代码可读性与可移植性，同时提高效率；
	- 相比直接写汇编，优化源代码能兼顾可读性、模块性和可移植性；

---
# 5.1 优化编译器的能力和局限性
编译器的任务不仅是把源代码翻译成机器码，还要**自动优化程序的性能**，比如：
- 让程序运行更快；
- 让程序占用更少的寄存器或内存；
- 减少分支跳转、缓存缺失等开销。
但这些优化**必须在不改变程序语义的前提下**进行，也就是说：
> 编译器“能优化的部分”，都是在 **逻辑完全等价** 的情况下。

而编译器能自动执行一些常规优化，尤其是对 **循环、常量、局部变量** 等部分，现代编译器（如 GCC、Clang、MSVC）都可以做到这些：

| 优化类型                              | 示例                               | 效果           |
| --------------------------------- | -------------------------------- | ------------ |
| **常量传播** (Constant Propagation)   | `int x = 3 * 5;` → `int x = 15;` | 消除不必要的运算     |
| **强度削弱** (Strength Reduction)     | `x * 8` → `x << 3`               | 用更快的操作代替慢操作  |
| **公共子表达式消除**                      | `a*b + a*b` → `t = a*b; t + t`   | 避免重复计算       |
| **死代码消除** (Dead Code Elimination) | 移除对结果无影响的代码                      | 减少无用执行       |
| **循环展开** (Loop Unrolling)         | 把循环多次迭代合并执行                      | 减少分支、提高指令并行性 |
| **寄存器分配优化**                       | 频繁使用的变量放寄存器                      | 减少内存访问       |
| **指令调度** (Instruction Scheduling) | 调整指令顺序避免流水线停顿                    | 提升 ILP 并行度   |

但是，编译器不能 “理解” 程序的语义意图，它的优化也有诸多限制：
1. **指针与别名分析的限制**：两个指针可能指向同一个内存位置的情况称为 **内存别名使用（memory aliasing）**。此时，就必须假设什么情况都有可能，这就限制了可能的优化策略；
2. **函数调用的副作用**：编译器无法知道被调用的函数是否修改了全局变量或指针所指内容，此时，编译器会假设最糟的情况，并保持所有的函数调用不变；
3. **跨模块、跨语言边界的优化难度**：不同的文件或库之间，编译器往往缺乏全局视野
	- 编译单元之间的优化（如函数内联）受限；
	- 链接时优化（LTO）虽可改善，但仍然有限。
4. **算法层面的优化无法自动完成**：编译器无法理解 “意图”，只能在 **实现层面微调**；

编译器的优化也分等级，一下以 GCC 为例：

| 优化等级  | 命令行选项   | 说明                |
| ----- | ------- | ----------------- |
| 无优化   | `-O0`   | 快速编译，便于调试         |
| 基础优化  | `-O1`   | 启用安全的局部优化         |
| 较强优化  | `-O2`   | 启用更多优化（寄存器、循环展开等） |
| 激进优化  | `-O3`   | 强化向量化、内联、ILP 等    |
| 链接时优化 | `-flto` | 跨文件全局优化           |

# 5.2 表示程序性能
引入度量标准 - **每元素的周期数(Cycles Per Element,CPE)**，作为一种表示程序性能并指导如何改进代码。CPE 这种度量标准使能够在更细节的级别上理解迭代程序的循环性能。这样的度量标准对执行重复计算的程序来说是很适当的，例如处理图像中的像素，或是计算矩阵乘积中的元素。

> “程序运行总时间 ≈ 固定开销 + 每元素花的时间 × 元素数”
> 当 **元素数** 足够大时，固定开销可以忽略，只需比较 CPE 大小。

更愿意用每个元素的周期数而不是每次循环的周期数来度量，这是因为**程序的根本目标是处理完 n 个数据需要多少时间**，如果用 “每次循环的周期数” 去比较，不同优化会改变循环次数（如循环展开、向量化等），这会导致**循环层面的指标不再可比**；  
因此，更合理的做法是用 **每个数据元素的平均周期数（CPE）** 来衡量性能，  
这样无论循环结构怎么变化，都能反映真实的“单位数据处理效率”。

# 5.3 程序示例
为了说明一个抽象的程序是如何被系统地转换成更有效的代码的，该节将使用一个基于图 5-3 所示向量数据结构的运行示例。

![[NoteAboutStudy/attachments/Pasted image 20251019223343.png]]

向量由两个内存块表示：头部和数据数组。头部是一个声明如下的结构：
```c
/*Create abstract data type for vector */
typedef struct{
	long len;
	data_t *data;
}vec_rec,*vec_ptr;
```

这个声明用 `data_t` 来表示基本元素的数据类型。在测试中，度量代码对于整数( C 语言的 `int` 和 `long`)和浮点数( C 语言的 `float` 和 `double`)数据的性能。为此，会分别为不同的类型声明编译和运行程序，就像这个例子对数据类型 `long`一样：`typedef long data_t;`，还会分配一个包含 `len` 个 `data_t` 类型对象的数组，来存放实际的向量元素。

其实这节就是根据程序示例来讲解优化程序，具体细节还是看书吧，主要是以下几点：
- CPE 是核心指标：衡量单位数据的代价；
- 理解**内存访问 vs 计算指令**谁是瓶颈；
- 利用**循环展开和多累加**打破依赖链，依赖链会限制流水线效率；
- 知道编译器能做什么、不能做什么，同时，编译器优化有限，手动展开与多累加更有效；
- 性能优化要基于**分析与实验**，不是猜测；

# 5.4 消除循环的低效率
把不会随循环变化的计算，移出循环体执行，从而避免重复执行。 -- 这类优化被称为 **代码移动(code motion)**。

例如：
- 常量表达式；
- 与循环无关的函数调用；
- 不依赖循环变量的中间结果。
这样可以显著减少重复计算，提高指令吞吐。

 ⚠️ 但编译器未必能自动做到：
- 编译器无法判断一个函数是否有 **副作用（side effect）**；
- 比如函数内部是否修改了全局变量；
- 所以它会 “保守地” 认为可能有副作用，不轻易移动调用。
因此，**程序员往往必须显式地帮助编译器完成代码移动。**

同时，循环低效率中也有个常见的问题 --  **渐近低效率**。
何为渐进低效率？在性能优化中，渐近效率指的是算法在输入规模增大时的增长趋势 -- 也就是时间复杂度或空间复杂度的变化规律。在编程中，某些代码片段在小规模数据下可能表现正常，但由于包含了重复或不必要的操作，随着输入规模增加，性能恶化速度远超预期。

# 5.5 减少过程调用
过程调用会带来开销，而且妨碍大多数形式的程序优化。

但是简单地消除函数调用，并一定能显著提升性能，因为程序性能往往受制于更深层的瓶颈，而不是表面上的函数调用开销。
- **函数调用开销相对很小**  
    在现代处理器中，函数调用的开销往往只占几条指令的时间，而循环内可能有几十上百条其他计算或内存操作，这些操作才是主要的瓶颈。
- **真正的瓶颈在于内存访问或流水线阻塞**  
    去掉函数调用不会改变这些核心问题。 
- **编译器优化可能自动内联函数**  
    如果编译器足够聪明，它会直接展开，那 “函数调用开销” 就消失了。人为修改代码反而可能破坏其他优化或缓存局部性。

# 5.6 消除不必要的内存引用
有的循环中可能会有多余内存读写，比如说，每次循环迭代都从内存中读取累积变量进行计算，再把结果写回内存，这样就会导致 **每次迭代都会有多余的内存访问，而这些访问的开销远大于计算本身。**

对于这种情况。通过引入一个局部变量，在寄存器中累积结果，**只在循环结束后再写回内存**。
- 循环内只需读取数组数据一次；
- 累积值保存在寄存器中。
这种方式将每次迭代的内存操作减少为**一次读**。

而编译器不能自动完成这个的原因在于编译器无法确定用户意图，因此只能采取**保守策略**，维持每次迭代的读写操作。（内存别名的问题）

# 5.7 理解现代处理器
到目前为止，所运用的优化都不依赖于目标机器的任何特性。这些优化只是简单地降低了过程调用的开销，以及消除了一些重大的 “妨碍优化的因素” ，这些因素会给优化编译器造成困难。

随着试图进一步提高性能，必须考虑利用处理器微体系结构的优化，也就是处理器用来执行指令的底层系统设计。要想充分提高性能，需要仔细分析程序，同时代码的生成也要针对目标处理器进行调整。

尽管如此，还是能够运用一些基本的优化，在很大一类处理器上产生整体的性能提高。在该节讲述的详细性能结果，对其他机器不一定有同样的效果，但是操作和优化的通用原则对各种各样的机器都适用。

虽然现代微处理器的详细设计超出了本书讲授的范围，对这些微处理器运行的原则有一般性的了解就足够能够理解它们如何实现指令级并行。两种下界描述了程序的最大性能。当一系列操作必须按照严格顺序执行时，就会遇到 **延迟界限（latency bound）**，因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。**吞吐量界限（throughput bound）** 刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。

---
## 5.7.1 整体操作
![[NoteAboutStudy/attachments/Pasted image 20251020213734.png]]

图 5-11 是现代微处理器的一个非常简单化的示意图。之前假想的处理器设计是不太严格地基于近期的 Intel 处理器的结构（和现在的比更不太严格了）。

这些处理器在工业界称为 **超标量（superscalar）**，意思是它可以在每个时钟周期执行多个操作，而且是 **乱序的（out-of-order）**，意思就是指令执行的顺序不一定要与它们在机器级程序中的顺序一致。

整个设计有两个主要部分：**指令控制单元（Instruction Control Unit，ICU）** 和 **执行单元（ExecutionUnit，EU）**。前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作；而后者执行这些操作。

和第 4 章中研究过的 **按序（in-order）** 流水线相比，乱序处理器需要更大、更复杂的硬件，但是它们能更好地达到更高的指令级并行度。

---
### 取指阶段
ICU 从 **指令高速缓存（instruction cache）** 中读取指令（指令高速缓存是一个特殊的高速存储器，它包含最近访问的指令）。为了避免停顿，通常，ICU 会在当前正在执行的指令很早之前取指，这样它才有足够的时间对指令译码，并把操作发送到 EU。

不过，一个问题是当程序遇到分支时，程序有两个可能的前进方向：
- 一种可能会选择分支，控制被传递到分支目标。
- 另一种可能是，不选择分支，控制被传递到指令序列的下一条指令。
现代处理器采用了一种称为 **分支预测（branch prediction）** 的技术，处理器会猜测是否会选择分支，同时还预测分支的目标地址。并利用 **投机执行（speculativeexecution）** 的技术，处理器会开始取出位于它预测的分支会跳到的地方的指令，并对指令译码，甚至在它确定分支预测是否正确之前就开始执行这些操作。如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并开始取出和执行另一个方向上的指令。

在处理器的结构图中，这些分支预测与取指逻辑通常由 **取指控制（fetch control）** 模块完成，用于决定下一步应从哪个地址取指令。

### 译码阶段
**指令译码** 逻辑接收实际的程序指令，并将它们转换成一组基本操作（有时称为 **微操作**）。每个这样的操作都完成某个简单的计算任务。而对于具有复杂指令的机器，比如 x86 处理器，一条指令可以被译码成多个操作。

关于指令如何被译码成操作序列的细节，不同的机器都会不同，这个信息可谓是高度机密。幸运的是，不需要知道某台机器实现的底层细节，也能优化自己的程序。

### 执行阶段
#### 操作执行
EU 接收来自取指单元的操作。通常，每个时钟周期会接收多个操作。这些操作会被分派到一组功能单元中，它们会执行实际的操作。这些功能单元专门用来处理不同类型的操作。

读写内存是由加载和存储单元实现的。加载单元处理从内存读数据到处理器的操作。这个单元有一个加法器来完成地址计算。类似，存储单元处理从处理器写数据到内存的操作。它也有一个加法器来完成地址计算。如图中所示，加载和存储单元通过 **数据高速缓存（data cache）** 来访问内存（数据高速缓存是一个高速存储器，存放着最近访问的数据值）

#### 结果暂存与数据转发
使用投机执行技术对操作求值，但是最终结果不会存放在程序寄存器或数据内存中，直到处理器能确定应该实际执行这些指令。分支操作被送到 EU，不是确定分支该往哪里去，而是确定分支预测是否正确。如果预测错误，EU 会丢弃分支点之后计算出来的结果。它还会发信号给分支单元，说预测是错误的，并指出正确的分支目的。在这种情况中，分支单元开始在新的位置取指。如在 3.6.6 节中看到的，这样的预测错误会导致很大的性能开销。在可以取出新指令、译码和发送到执行单元之前，要花费一点时间。

图 5-11 说明不同的功能单元被设计来执行不同的操作。那些标记为执行 “算术运算” 的单元通常是专门用来执行整数和浮点数操作的不同组合。随着时间的推移，在单个微处理器芯片上能够集成的晶体管数量越来越多，后续的微处理器型号都增加了功能单元的数量以及每个单元能执行的操作组合，还提升了每个单元的性能。由于不同程序间所要求的操作变化很大，因此，算术运算单元被特意设计成能够执行各种不同的操作。比如，有些程序也许会涉及整数操作，而其他则要求许多浮点操作。如果一个功能单元专门执行整数操作，而另一个只能执行浮点操作，那么，当程序主要使用某一类运算时，其他单元将无法被有效利用，从而降低整体的硬件资源利用率。

#### 指令退役与寄存器重命名
在 ICU 中，**退役单元（retirementunit）** 记录正在进行的处理，并确保它遵守机器级程序的顺序语义。图 5-11 中展示了一个寄存器文件，它包含整数、浮点数和最近的 SSE 和 AVX 寄存器，是退役单元的一部分，因为退役单元控制这些寄存器的更新。指令译码时，关于指令的信息被放置在一个先进先出的队列中。这个信息会一直保持在队列中，直到发生以下两个结果中的一个。
- 首先，一旦一条指令的操作完成了，而且所有引起这条指令的分支点也都被确认为预测正确，那么这条指令就可以 **退役（retired）** 了，所有对程序寄存器的更新都可以被实际执行了。
- 另一方面，如果引起该指令的某个分支点预测错误，这条指令会被 **清空（flushed）**，丢弃所有计算出来的结果。通过这种方法，预测错误就不会改变程序的状态了。
正如已经描述的那样，任何对程序寄存器的更新都只会在指令退役时才会发生，只有在处理器能够确信导致这条指令的所有分支都预测正确了，才会这样做。为了加速一条指令到另一条指令的结果的传送，许多此类信息是在执行单元之间交换的，即图中的 “操作结果”。如图中的箭头所示，执行单元可以直接将结果发送给彼此。这是4.5.5节中简单处理器设计中采用的数据转发技术的更复杂精细版本。

而控制操作数在执行单元间传送的最常见的机制称为 **寄存器重命名（register renaming）**:
1. 当一条更新寄存器 `r` 的指令译码时，产生标记 `t`，得到一个指向该操作结果的唯一的标识符。
2. 条目 `(r，t)` 被加入到一张表中，该表维护着每个程序寄存器 `r` 与会更新该寄存器的操作的标记 `t` 之间的关联。
3. 当随后以寄存器 `r` 作为操作数的指令译码时，发送到执行单元的操作会包含 `t` 作为操作数源的值。
4. 当某个执行单元完成第一个操作时，会生成一个结果 `(v，t)`，指明标记为 `t` 的操作产生值。
5. 所有等待 `t` 作为源的操作都能使用作为源值，这就是一种形式的数据转发。
通过这种机制，值可以从一个操作直接转发到另一个操作，而不是写到寄存器文件再读出来，使得第二个操作能够在第一个操作完成后尽快开始。

重命名表只包含关于有未进行写操作的寄存器条目。当一条被译码的指令需要寄存器 `r`，而又没有标记与这个寄存器相关联，那么可以直接从寄存器文件中获取这个操作数。

有了寄存器重命名，即使只有在处理器确定了分支结果之后才能更新寄存器，也可以预测着执行操作的整个序列。

## 5.7.2 功能单元的性能
![[NoteAboutStudy/attachments/Pasted image 20251022221245.png]]
如图 5-12 提供了 `Intel Core i7 Haswell` 参考机的一些算术运算的性能，有的是测量出来的，有的是引用 `Intel` 的文献。这些时间对于其他处理器来说也是具有代表性的。每个运算都是由以下这些数值来刻画的：
- **延迟（latency）**，它表示完成运算所需要的总时间；
- **发射时间（issue time）**，它表示两个连续的同类型的运算之间需要的最小时钟周期数；
- **容量（capacity）**，它表示能够执行该运算的功能单元的数量。

可以看到：
- 从整数运算到浮点运算，延迟是增加的；
- 加法和乘法运算的发射时间都为 1，意思是说在每个时钟周期，处理器都可以开始一条新的这样的运算：
	- 这种很短的发射时间是通过使用流水线实现的。流水线化的功能单元实现为一系列的 **阶段（stage）**，每个阶段完成一部分的运算；`例如，一个典型的浮点加法器包含三个阶段（所以有三个周期的延迟）：一个阶段处理指数值，一个阶段将小数相加，而另一个阶段对结果进行舍入。`
	- 算术运算可以连续地通过各个阶段，而不用等待一个操作完成后再开始下一个。只有当要执行的运算是连续的、逻辑上独立的时候，才能利用这种功能；
	- 发射时间为 1 的功能单元被称为 **完全流水线化的（fully pipelined）**：每个时钟周期可以开始一个新的运算。出现容量大于 1 的运算是由于有多个功能单元，就如前面所述的参考机一样；
- 除法器（用于整数和浮点除法，还用来计算浮点平方根）不是完全流水线化的 -- 它的发射时间等于它的延迟。这就意味着在开始一条新运算之前，除法器必须完成整个除法。而对于除法的延迟和发射时间是以范围的形式给出的，因为某些被除数和除数的组合比其他的组合需要更多的步骤。除法的长延迟和长发射时间使之成为了一个相对开销很大的运算；

表达发射时间的一种更常见的方法是指明这个功能单元的最大 **吞吐量**，定义为发射时间的倒数：
- 一个完全流水线化的功能单元有最大的吞吐量，每个时钟周期一个运算，而发射时间较大的功能单元的最大吞吐量比较小；
- 具有多个功能单元可以进一步提高吞吐量；
对一个容量为 *C*，发射时间为 *I* 的操作来说，处理器可能获得的吞吐量为每时钟周期 *C/I* 个操作。比如，参考机可以每个时钟周期执行两个浮点乘法运算。本书将说明如何利用这种能力来提高程序的性能。

电路设计者可以创建具有各种性能特性的功能单元。创建一个延迟短或使用流水线的单元需要较多的硬件，特别是对于像乘法和浮点操作这样比较复杂的功能。因为微处理器芯片上，对于这些单元，只有有限的空间，所以 CPU 设计者必须小心地平衡功能单元的数量和它们各自的性能，以获得最优的整体性能。设计者们评估许多不同的基准程序，将大多数资源用于最关键的操作。

如图 5-12 表明的那样，在 `Core i7 Haswell` 处理器的设计中，整数乘法、浮点乘法和加法被认为是重要的操作，即使为了获得低延迟和较高的流水线化程度需要大量的硬件。另一方面，除法相对不太常用，而且要想实现低延迟或完全流水线化是很困难的。

这些算术运算的延迟、发射时间和容量会影响合并函数的性能。通过 CPE 值的两个基本界限来描述这种影响：

![[NoteAboutStudy/attachments/Pasted image 20251022223425.png]]

- **延迟界限** 给出了任何必须按照严格顺序完成合并运算的函数所需要的最小 CPE 值。
- 根据功能单元产生结果的最大速率，**吞吐量界限** 给出了 CPE 的最小界限。

例如，因为只有一个整数乘法器，它的发射时间为 1 个时钟周期，处理器不可能支持每个时钟周期大于 1 条乘法的速度。另一方面，四个功能单元都可以执行整数加法，处理器就有可能持续每个周期执行 4 个操作的速率。不幸的是，因为需要从内存读数据，这造成了另一个吞吐量界限。两个加载单元限制了处理器每个时钟周期最多只能读取两个数据值，从而使得吞吐量界限为 0.50 。本书会展示延迟界限和吞吐量界限对合并函数不同版本的影响。

## 5.7.3 处理器操作的抽象模型
作为分析在现代处理器上执行的机器级程序性能的一个工具，使用程序的 **数据流（data-flow）** 表示，这是一种图形化的表示方法，展现了不同操作之间的数据相关是如何限制它们的执行顺序的。这些限制形成了图中的 **关键路径（critical path）**，这是执行一组机器指令所需时钟周期数的一个下界。

### 从机器级代码到数据流图
程序的数据流表示是非正式的。只是用它来形象地描述程序中的数据相关是如何主宰程序的性能的。

**数据流图**
- 每个操作（如 `load`, `mul`, `add`, `cmp`）被看作图中的一个节点；
- 操作之间的数据依赖（一个操作的输出是另一个的输入）用箭头连接；
- 通过这个图，可以直观看到程序执行时哪些操作**必须顺序进行**、哪些可以**并行执行**；

**寄存器分类（在循环中）**
- **只读**：这些寄存器只用作源值，可以作为数据，也可以用来计算内存地址，但是在循环中它们是不会被修改的；
- **只写**：这些寄存器作为数据传送操作的目的；
- **局部**：这些寄存器在循环内部被修改和使用，选代与迭代之间不相关，也就说是在单次迭代之内的；
- **循环**：对于循环来说，这些寄存器既作为源值，又作为目的，一次迭代中产生的值会在另一次选代中用到；
> 性能的关键在于这些“循环寄存器”之间的依赖链。

**数据相关链**：每次循环迭代都会用到上次迭代的 `%xmm0`（累积值）与 `%rdx`（索引），所以它们形成了**从旧值到新值的依赖链**，因此这条链的总延迟决定了**每次循环最少需要多少个周期**。

也就是说：
- **程序性能由数据相关决定，而不是代码量。**
- **关键路径的延迟 L = 程序性能的下界（CPE）。**
- **只要循环中存在依赖链，就无法通过指令并行或流水线完全掩盖延迟。**
- 对不同类型运算，只要延迟大于 1（如浮点乘、除），CPE 就等于它的延迟。

### 其他性能因素
> **关键路径决定理论下界，但实际 CPE 往往更高。** 因为：
- 数据流分析给出的关键路径（延迟 L）只是**理想情况的最小周期数**。
- 而实际测得的 CPE 比理想值要慢。
    
所以除了数据相关，**硬件层面的资源竞争**也在限制性能。

#### 造成偏差的两个主要因素
1️⃣ **功能单元数量有限**
- CPU 中执行不同操作（加法、加载、存储）的单元数量有限。
- 如果多个操作同时需要同一类型的单元，就会出现等待，降低并行度。
    
2️⃣ **数据传输带宽有限**
- 即使功能单元够快，寄存器/缓存/执行单元之间的数据传输速度也可能不足，  
    导致某些操作无法及时获得输入数据。

综上所述，优化方向为：通过**重组代码结构**、**引入指令级并行（ILP）**，减少依赖链、让更多操作并行执行，使性能受限于“吞吐量界限”而非“延迟界限”。

# 5.8 循环展开
循环展开是一种程序变换，通过增加每次迭代计算的元素的数量，即让处理器能在同一时刻执行更多指令，减少循环的迭代次数，从而突破由数据相关造成的性能瓶颈。

因为每次循环迭代都依赖上一次的结果，而这种 “链式依赖” 导致程序执行被**延迟界限（latency bound）** 限制，要想加速，必须**打破或减少这种依赖链**，循环展开就是做到这点的主要手段。

假设原始循环如下：
```c
for (i = 0; i < n; i++)      
	acc = acc + data[i];
```
每次迭代只处理一个元素，循环展开把它变成：
```c
for (i = 0; i < n; i += 2) {     
	acc0 = acc0 + data[i];     
	acc1 = acc1 + data[i+1];
	} 
acc = acc0 + acc1;
```
1. **展开了循环体**（每次迭代处理两个元素），
2. **用多个累加变量（acc0、acc1）** 分摊依赖，
3. 让两条独立的加法链可以并行执行。
展开后：
- 原来只有一条依赖链（`acc → acc`），
- 现在变成两条独立的链（`acc0`、`acc1`）。
    
处理器就能在同一时刻执行多条加法操作，结果：
> CPE 从 ≈L（延迟界限）  
> 下降到 ≈1（吞吐量界限）。

循环展开实质上是**以空间换时间**：
- 多用几个寄存器保存多个部分和（partial sums），
- 减少每条依赖链的长度。

一般来说，向量长度不一定是 2 的倍数。想要使代码对任意向量长度都能正确工作，可以从两个方面来解释这个需求:
- 首先，要确保第一次循环不会超出数组的界限。对于长度为 `n` 的向量，将循环界限设为 `n-1`;
- 然后，保证只有当循环索引 `i` 满足 `i< n-1` 时才会执行这个循环，因此最大数组索引 `i+1` 满足 `i+1<(n-1)+1=n`;

把这个思想归纳为对一个循环按任意因子 `k` 进行展开，由此产生 `k×1` 循环展开。为此，
- 主循环上限设为 `n-k+1`，在主循环内对元素 `i` 到 `i+k-1` 应用合并运算。每次迭代，循环索引 `i` 加 `k`。那么最大循环索引 `i+k-1` 会小于 `n`；
- 在尾部循环，处理剩下的 `n % k` 个元素，每次处理 1 个。这个循环体将会执行 `0~k-1` 次；

---
但是，循环展开不是“越大越好”。影响因素包括：

|因素|说明|
|---|---|
|寄存器数量|展开因子过大，寄存器不够用，会导致溢出到内存，反而变慢。|
|功能单元数量|若CPU只有2个加法单元，展开4倍也没意义。|
|编译器调度能力|编译器必须能把多条指令交错执行。|
|代码局部性|展开会使代码体积变大，可能影响指令缓存效率。|
> [!info]- 让编译器展开循环
> 编译器可以很容易地执行循环展开。只要优化级别设置得足够高，许多编译器都能例行公事地做到这一点。用优化等级 3 或更高等级调用 GCC，它就会执行循环展开。

# 5.9 提高并行性
在此，程序的性能是受运算单元的延迟限制的。但是，执行加法和乘法的功能单元是完全流水线化的，这意味着它们可以每个时钟周期开始一个新操作，并且有些操作可以被多个功能单元执行。硬件具有以更高速率执行乘法和加法的潜力，但是代码不能利用这种能力，即使是使用循环展开也不能，这是因为将累积值放在一个单独的变量中，所以在前面的计算完成前，都不能计算这个变量的新值。

于是 —— 即使功能单元能每个周期开始新操作，  程序也只能**每 L 个周期**开始一次（L 为运算延迟）。

这节就是讲述如何打破这种顺序相关，得到比延迟界限更好性能的方法。

---
### 5.9.1 多个累积变量
对于一个可结合和可交换的合并运算来说，比如说整数加法或乘法，可以通过将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能。

![[NoteAboutStudy/attachments/Pasted image 20251027215949.png]]
图 5-21 展示的是使用这种方法的代码。它既使用了两次循环展开，以使每次迭代合并更多的元素，也使用了两路并行:
- 将索引值为偶数的元素累积在变量 `acc0` 中；
- 索引值为奇数的元素累积在变量 `acc1` 中。
因此，将其称为 “2×2循环展开”。同 5.8 循环展开 一样，还包括了第二个循环，对于向量长度不为 2 的倍数时，这个循环要累积所有剩下的数组元素。然后，对 `acc0` 和 `acc1` 应用合并运算，计算最终的结果。

比较只做循环展开和既做循环展开同时也使用两路并行这两种方法，得到下面的性能：整数乘、浮点加、浮点乘改进了约 2 倍，而整数加也有所改进。特别的是，打破了由延迟界限设下的限制。处理器不再需要延迟一个加法或乘法操作以待前一个操作完成。

原因是：原来每条关键路径长为 `n`，现在变成两条各为 `n/2`，因此，延迟界限 CPE 从 `L` 降到约 `L/2`。

可以将多个累积变量变换归纳为将循环展开 `k` 次，以及并行累积 `k` 个值，得到 $k*k$ 循环展开。而当 `k` 值足够大时，程序在所有情况下几乎都能达到吞吐量界限。

> [!tip]- 浮点乘与浮点加的吞吐量
> 即使乘法是更加复杂的操作，在浮点乘上达到的吞吐量几乎是浮点加可以达到的两倍。

通常，只有保持能够执行该操作的所有功能单元的流水线都是满的，程序才能达到这个操作的吞吐量界限。对延迟为 `L`，容量为 `C` 的操作而言，这就要求循环展开因子 $k ≥ C × L$。

在 $k*k$ 循环展开变换时，必须考虑是否要保留原始函数的功能，对此：
- **整数操作**（补码加/乘）是可交换、可结合的，所以多累积不会改变结果；编译器可以自动优化。
- **浮点操作**（加/乘）不严格可结合，可能因舍入或溢出导致结果略不同。  
    → 一般情况下差异很小，但对极端数据可能有影响。  
    → 因此大多数编译器不会自动进行这种变换，需人工选择。

### 5.9.2 重新结合变换

