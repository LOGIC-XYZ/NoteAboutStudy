**从某种意义上来说，本书的目的就是了解，当在系统中执行程序时，系统会发生什么，以及为什么会这样**

# 1.1 信息就是位 + 上下文
系统中所有的信息一包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。

# 1.2 程序被其他程序翻译成不同的格式
程序的生命周期通常是从一个高级语言开始的，以便人能读懂。但是，为了能在系统上运行程序，需要机器能读懂，于是每条语句都必须被其他程序转化为一系列低级的**机器语言**指令。然后这些指令按照一种称为**可执行文件目标程序**的格式打包好，并以二进制磁盘文件的形式存放起来。目标程序也称为**可执行目标文件**。（就比如编译cpp文件会产生一个exe文件，运行是运行这个exe文件）
这个翻译过程可分为四个阶段完成，如图![[../../attachments/Pasted image 20250825161218.png]]执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统。
 - 预处理阶段。根据以字符#开头的命令，修改原始的C程序。比如 `hello.c` 中第1行 `#include<stdio.h>` 命令告诉预处理器读取系统头文件 `stdio.h`的内容，并把它直接插入程序文本中。结果就得到了另一个C程序。
 - 编译阶段。将上一个阶段的文本文件翻译成汇编语言程序的文本文件，每一条语句都以一种文本格式描述一条低级机器语言指令。
 - 汇编阶段。将上一阶段的文本文件翻译成机器语言指令，并把这些指令打包成一种叫做**可重定位目标程序**的格式，并将结果保存在目标文件中（该文件是个二进制文件）
 - 链接阶段。链接其他需要使用的单独的预编译好了的目标文件，从而得到可执行文件，可以被加载到内存中，由系统执行。

# 1.3 了解编译系统如何工作是大有益处的
益处：优化程序性能；理解链接时出现的错误；避免安全漏洞

# 1.4 处理器读并解释储存在内存中的指令
在 Unix 系统上运行可执行文件，是通过 Shell 来运行。（[[../../Shell/The Shell|The Shell]]）

## 1.4.1 系统的硬件组成
![[../../attachments/Pasted image 20250825163037.png]]
### 1. 总线
Bus -- 携带信息字节并负责在各个部件间传递
### 2. I/O 设备
是系统与外部世界的联系通道。每个 I/O 设备都通过一个控制器与适配器与 I/O 总线相连。控制器与适配器的区别主要在于它们的封装方式：控制器是 I/O 设备本身或者系统的主板上的芯片组，而适配器则是一块插在主板插槽上的卡
### 3. 主存
是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存取存储器(DRAM)芯片组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的
### 4. 处理器
- 中央处理单元(CPU)，简称处理器，是解释（或执行）存储在主存中指令的引擎
- 处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器(PC)
- 在任何时刻，PC 都指向主存中的某条机器语言指令（即含有该条指令的**地址**）。从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一条指令
- 处理器看上去是按照一个非常简单的指令执行模型来操作的，这个模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行，而执行一条指令包含执行一系列的步骤。处理器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新 PC ，使其指向下一条指令，而这条指令并不一定和在内存中刚刚执行的指令相邻
- 这样的简单操作并不多，它们围绕着主存、寄存器文件和算术/逻辑单元(ALU)进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。ALU 计算新的数据和地址值
- 处理器看上去是它的指令集架构的简单实现，但是实际上现代处理器使用了非常复杂的机制来加速程序的执行。因此，我们将处理器的指令集架构和处理器的微体系结构区分开来：指令集架构描述的是每条机器代码指令的效果；而微体系结构描述的是处理器实际上是如何实现的

## 1.4.2 运行程序
![[../../attachments/Pasted image 20250825165719.png]]![[../../attachments/Pasted image 20250825165744.png]]![[../../attachments/Pasted image 20250825165757.png]]

# 1.5 高速缓存至关重要
根据 1.4.2 的过程，我们了解到系统花费了大量的时间把信息从一个地方挪到另一个地方。而较大的存储设备要比较小的存储设备运行得慢，而快速设备的造假远高于同类的低速设备。类似地，一个典型的寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。更麻烦的是，随着半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。
针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为**高速缓存存储器**（cache memory，简称 cache 或高速缓存），作为暂时的集结区域，存放处理器近期可能会需要的信息。

## 1.6 存储设备形成层次结构
每个计算机系统中的存储设备都被组织成了一个**存储器层次结构**，如图![[../../attachments/Pasted image 20250825171303.png]]该层次结构的主要思想是上一层的存储器作为第一层的高速缓存。

## 1.7 操作系统管理硬件
当运行程序时，并没有直接访问硬件设备，而是依靠**操作系统**提供的服务，我们可以把操作系统看成是应用程序和硬件之间插入的一层软件，而所有的应用程序对硬件的尝试都必须通过操作系统。![[../../attachments/Pasted image 20250825171741.png]]
操作系统有两个基本功能：(1)防止硬件被失控的应用程序滥用；(2)向应用程序
提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。
### 1.7.1 进程
**进程**是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而**并发运行**，则是说一个进程的指令和个进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论是在单核还是多核系统中，一个CPU看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制称为**上下文切换**。
