---
tags:
  - CSAPP
---
一个系统中的进程是与其他进程共享 CPU 和主存资源的：
 - 随着对 CPU 需求的增长，进程就会变慢；
 - 但是如果太多的进程需要太多的内存，就会导致一些无法运行，并且一个进程误写了另一个进程使用的内存，就可能会导致错误；

为了更有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，称为 **虚拟内存(VM)**：
> VM = **硬件异常** + **硬件地址翻译** + **主存** + **磁盘文件** + **内核软件** 的交互协作
> 为 **每个进程** 提供一个大的、连续的、私有的地址空间。

虚拟内存提供了三个重要的能力：
 1. **把主存看作磁盘的高速缓存**
	- 主存只保存活动区域；
	- 磁盘保存完整地址空间；
	- 根据需要在磁盘和主存间传送数据（就不会内存不够了）；
 2. **给每个进程提供一致的地址空间**
	- 不用关心物理内存是否碎片；
	- 简化了内存管理与程序设计；
 3. **保护每个进程的地址空间不被破坏**
	- 一个进程不能访问其他的进程的内存；
	- 错误访问直接触发异常；

为什么需要理解虚拟内存：
 - 虚拟内存遍及计算机系统的所有层面，在硬件异常、汇编器、链接器、加载器、共享对象、文件和进程的设计中都扮演者重要的角色，是理解系统是如何工作的重要一环；
 - 虚拟内存使得应用程序可以，按需创建/销毁内存、把文件映射成内存、多进程共享内存、通过读写内存来读写文件；
 - 同时，每次应用程序引用一个变量、间接引用一个指针、或者调用像 `malloc/free` 这样的动态分配程序时，就会和虚拟内存发生交互。如果使用不当，就会导致错误；

本章将从 VM 如何工作 以及 程序如何使用 VM 两个部分来讲述：

---
# 9.1 物理和虚拟寻址
计算机系统的主存是一个 **由连续的字节大小的单元** 组成的数组，每个字节都有一个唯一的 **物理地址(Physical Address，PA)**。

CPU 访问内存最自然的方式就是通过物理地址，这种方式称为 **物理寻址(physical addressing)**，如图 9-1 所示为一个物理寻址的示例：
![[NoteAboutStudy/attachments/Pasted image 20260117204804.png]]
CPU 执行一条加载指令（读取从物理地址 4 处开始的 4 字节字），执行时会生成一个有效物理地址，通过内存总线传递给主存，然后主存返回数据给 CPU（CPU 会将它存放在一个寄存器中）。

现代处理器使用的是称为 **虚拟寻址(virtual addressing)** 的寻址形式，如图 9-2 所示：
![[NoteAboutStudy/attachments/Pasted image 20260117204945.png]]
CPU 通过生成一个 **虚拟地址(Virtual Address，VA)** 来访问内存，而 VA 在访问主存前会先被转换为 PA。

将一个虚拟地址转换为物理地址的过程称为 **地址翻译(address translation)**，地址翻译需要 CPU 硬件和操作系统之间的紧密合作：
 - CPU 芯片上称为 **内存管理单元(Memory Management Unit，MMU)** 硬件负责工作；
 - 利用由操作系统维护的存放在主存中的描述 VA -> PA 的映射关系的查询表来动态翻译虚拟地址；

# 9.2 地址空间
**地址空间(address space)** 是一个非负整数地址的有序集合（用于给内存字节编号的）。

如果地址空间中的整数是连续的，则称为 **线性地址空间(linear address space)**。为了简化讨论，总是假设使用的是线性地址空间。

在一个带虚拟内存的系统中，CPU 从一个有 $N=2^n$ 个地址的地址空间中生成虚拟地址，这个地址空间称为 **虚拟地址空间(virtual address space)**：{$0,1,2,……,N-1$}。

一个地址空间的大小是由最大地址所需要的位数来描述的，例如：
 - 最大虚拟地址需要 **n 位二进制数**表示
 - 地址总数是 **2ⁿ**
则称之为 $n$ 位地址空间（现代系统通常支持 32 位或者 64 位虚拟地址空间）。

**物理地址空间(physical address space)** 则对应系统中物理内存的 $M$ 个字节：{$0,1,2,……,M-1$} （M 不要求是 2 的幂，但为了简化讨论，通常还是假设 $M=2^m$）。

有了地址空间，主存中的每个字节都由一个选自 虚拟地址空间 的 VA 和 一个选自 物理地址空间 的 PA。

# 9.3 虚拟内存作为缓存的工具
从概念模型上看，虚拟内存可以被视为一个存放在磁盘上的、由 $N$ 个连续的字节大小的单元组成的数组，其中每个字节都有唯一的虚拟地址作为索引，且主存中缓存该数组中 “当前活跃” 的一部分。

和存储器层次结构中其他缓存一样，将数据分割为块，作为磁盘（较低层次）和主存（较高层次）之间的传输单元：
 - VM 系统将虚拟内存分割为大小固定的块，称为 **虚拟页(Virtual Page，VP)** ，每个的大小为 $P=2^p$ 字节；
 - 物理内存也被切割为同样大小的块，称为 **物理页(Physical Page，PP)** 或 **页帧(page frame)**，大小同样为 $P$ 字节；
VP 和 PP 一致，以确保地址翻译成立。

在任意时刻，所有虚拟页被划分为三个互斥集合：
 - **未分配** -- VM 系统尚未分配（或者创建）的页，没有数据，故不占用磁盘空间；
 - **未缓存** -- 未缓存在物理内存中的已分配页，页存在于磁盘上，但尚且不在主存中，访问时会触发缺页异常；
 - **缓存** -- 当前已缓存在物理内存中的已分配页，可直接访问；

---
## 9.3.1 DRAM 缓存的组织结构
为了清晰讲解存储层次结构中不同的缓存概念，将位于 CPU 和主存之间的 L1、L2 和 L3 高速缓存称为 SRAM 缓存，将虚拟内存系统的缓存称为 DRAM 缓存（它在主存中缓存虚拟页）。

DRAM 缓存一旦不命中，就要去访问磁盘，而访问磁盘代价极其昂贵：
 - 故 VP 通常很大，一次多搬运数据；
 - 故 缓存为全相联，即任何虚拟页都可以放置在任何物理页中；
 - 故 不命中的替换策略是操作系统使用复杂的替换算法；
 - 故 使用 ==写回==，而不是直写，避免每次写内存都要同步写磁盘，而是只发生在 DRAM ，再一次性写回；

## 9.3.2 页表
同任何缓存一样，虚拟内存系统需要一种方法来判定一个虚拟页是否缓存在 DRAM 中的某个地方：
 - 如果是，还需要知道该虚拟页存放在哪个物理页中；
 - 如果不命中，需要判断该虚拟页存放在磁盘的哪个位置，并在物理内存中选择一个牺牲页，然后将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页；
这些功能由软硬件联合提供，包括操作系统软件、MMU（内存管理单元）中的地址翻译硬件和一个存放在物理内存中称为 **页表(page table)** 的数据结构。
 - 页表将虚拟页映射到物理页；
 - 每次地址翻译硬件将一个虚拟地址转换为物理地址时，都需要读取页表；
 - 操作系统则负责维护页表内容，以及在磁盘和 DRAM 之间传送页；

如图 9-4 所示为一个页表的基本组织结构，页表就是一个 **页表条目(Page Table Entry，PTE)** 的数组，虚拟地址空间中的每个页在页表中都有一个 PTE，有多少个页就有多少个 PTE。
![[NoteAboutStudy/attachments/Pasted image 20260125195850.png]]
本节做了极度简化，假设 PTE 只有两部分：
 1. 有效位（valid bit）
	- 1：该虚拟页 **当前在 DRAM 中**
	- 0：不在 DRAM 中
 2. 地址字段
    - valid = 1：地址字段 → **物理页帧起始地址**
    - valid = 0：
        - 地址为空 → 页还没分配
        - 地址非空 → 页在磁盘上的位置

## 9.3.3 页命中
**CPU 访问的虚拟页已经在 DRAM 中**，因此**不需要触发缺页异常，不需要操作系统介入**，地址翻译由 MMU 通过页表将虚拟地址翻译为物理地址（将在 9.6 中详细描述），再直接从 DRAM 中取数据，这样称为 **页命中**。

## 9.3.4 缺页
DRAM 缓存不命中称为 **缺页(page fault)**，MMU 在检查页表项有效位时发现 0，地址翻译硬件触发缺页异常，并将控制权转交给内核的缺页异常处理程序，由操作系统来选择牺牲页，如果该牺牲页被修改过还需写回磁盘（没有就直接丢弃），然后从磁盘中复制目标页到 DRAM 中替换牺牲页，异常处理程序返回，重新执行导致缺页的指令。

| 缓存（SRAM）术语 | 虚拟内存术语         |
| ---------- | -------------- |
| 块（block）   | 页（page）        |
| 不命中（miss）  | 缺页（page fault） |
| 从下层取数据     | 页面调入（page-in）  |
| 写回下层       | 页面调出（page-out） |
| 缓存管理策略     | 页面调度策略         |

当有不命中发生时，才换入页面的策略称为 **按需页面调度(demand paging)** (现代通用操作系统都使用使用按需分页)。

## 9.3.5 分配页面
如图 9-8 所示为操作系统分配一个新的虚拟内存页时对页表的影响：
![[NoteAboutStudy/attachments/Pasted image 20260125204832.png]]
分配一个虚拟页时，操作系统只是在磁盘上为它分配空间，并更新页表，并不会立刻把它放进 DRAM。

## 9.3.6 局部性在虚拟内存中
尽管在整个运行过程中程序引用的不同的页面的总数可能超出物理内存总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的 **活动页面(active page)** 集合上工作，这个集合称为 **工作集(working set)** 或者 **常驻集合(resident set)**。在第一次访问时，将工作集调度到内存中之后，后续的访问几乎都是页命中，不会产生额外的磁盘流量，也就会提升虚拟内存的性能。

但是当 工作集的大小超出了物理内存的大小，就会导致 **抖动(thrasing)**，页面将不断地换进换出（如果一个程序性能很慢，就要考虑是不是这种情况了）。

# 9.4 虚拟内存作为内存管理的工具
在前面都说的是有一个单独的页表，将一个虚拟地址空间映射到物理地址空间，实际上，操作系统为每个进程提供了一个独立的页表，也就是一个独立的虚拟地址空间，同一个虚拟地址，在不同进程中可以映射到**完全不同的物理页**，如图 9-9 所示：
![[NoteAboutStudy/attachments/Pasted image 20260126205026.png]]
多个虚拟页面可以映射到同一个共享物理页面上。

VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配：
 - **简化链接**。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的位置，这样的一致性简化了链接器的设计和实现；
 - **简化加载**。
	1. 当要把目标文件中 `.text` 和 `.data` 节加载到一个新创建的进程中，Linux 加载器为代码和数据分配虚拟页，并标记为 **未缓存** 的，把 PTE 指向磁盘文件中的位置，并没有把代码或数据复制到内存中；
	2. 在每个页被初次引用时，要么是 CPU 取指令时执行，要么是正在执行的指令访问某个数据地址，按需调度；
	3. 将一组连续的虚拟页映射到文件的某个位置，称为 **内存映射(memory mapping)**，Linux 提供称为 `mmap` 的系统调用，允许用户程序自己做内存映射（将在 9.8 中描述应用级内存映射）；
 - **简化共享**。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，不与其他进程共享，然而在一些情况中，需要进程共享代码和数据，此时操作系统将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本；
 - **简化内存分配**。当一个运行在用户进程中的程序要求额外的堆空间时，操作系统分配 $k$ 个连续的虚拟页，并将它们映射到物理内存中任意位置的 $k$ 个物理页，且这些物理页不需要连续；

# 9.5 虚拟内存作为内存保护的工具
任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问：
 - 不应该允许一个用户进程修改它的只读代码段；
 - 不应该允许它读或修改任何内核中的代码和数据结构；
 - 不应该允许它读或者写其他进程的私有内存；
 - 不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）；

因为每次 CPU 生成一个地址时，地址翻译硬件都会读 PTE，所以通过在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问，如图 9-10 所示：
![[NoteAboutStudy/attachments/Pasted image 20260126225817.png]]
在这个示例中，每个 PTE 中添加了三个许可位：
 - SUP 位表示进程是否必须运行在内核（超级用户）模式下才能访问该页（运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 0 的页面）；
 - READ 位和 WRITE 位控制对页面的读和写访问；

如果一条指令违反了这些许可条件，那么 CPU 就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。Linux shell 一般将这种异常报告为“段错误（segmentation fault）”。

# 9.6 地址翻译
该节主要讲述地址翻译的基础知识，以了解硬件在支持虚拟内存中的角色，但是省略了大量细节，包括时序相关的细节（这部分细节对硬件设计来说是非常重要的，但超出本书讨论范围）。

如图 9-11 概括了在本节中将要使用的所有符号：
![[NoteAboutStudy/attachments/Pasted image 20260130201859.png]]

形式上来说，地址翻译是一个 $N$ 元素的虚拟地址空间(VAS) 中的元素和一个 $M$ 元素的物理地址空间(PAS) 中的元素之间的映射 -- $MAP:VAS→PAS∪∅$，含义：
 - 虚拟地址 **要么** 映射到某个物理地址；
 - **要么** 当前不在物理内存中（Ø → 缺页）；

如图 9-12 所示为 MMU 如何利用页表来实现映射：
![[NoteAboutStudy/attachments/Pasted image 20260130202707.png]]
CPU 中的一个控制寄存器 -- **页表基址寄存器(Page Table Base Register，PTBR)** 指向当前进程页表的起始地址。$n$ 位的虚拟地址包含两个部分：
 - 一个 $p$ 位的 **虚拟页面偏移(Virtual Page Offset，VPO)**；
 - 一个 $(n-p)$ 位的 **虚拟页号(Virtual Page Number，VPN)**；
MMU 利用 VPN 来选择适当的 PTE。将页表条目中 **物理页号(Physical Page Number，PPN)** 和虚拟地址中的 VPO 串联起来，就得到相对应的物理地址。同时，因为物理和虚拟页面都是 $P$ 字节的，所以 **物理页面偏移(Physical Page Offset，PPO)** 和 VPO 是相同的。

如图 9-13a 展示了当页面命中时，CPU 硬件执行的步骤（页命中完全是由硬件来处理的）：
	![[NoteAboutStudy/attachments/Pasted image 20260130203610.png]]
 1. 处理器生成一个虚拟地址，并传送给 MMU；
 2. MMU 生成 PTE 地址（PTEA），并从 高速缓存/内存 请求适当的 PTE；
 3. 高速缓存/内存 向 MMU 返回 PTE；
 4. MMU 构造物理地址 PA 传送给 高速缓存/内存；
 5. 高速缓存/内存 返回所请求的数据字给处理器；

如图 9-13b 展示了处理缺页时硬件和操作系统协作完成的步骤：
	![[NoteAboutStudy/attachments/Pasted image 20260130204356.png]]
 1. 处理器生成一个虚拟地址，并传送给 MMU；
 2. MMU 生成 PTE 地址（PTEA），并从 高速缓存/内存 请求适当的 PTE；
 3. 高速缓存/内存 向 MMU 返回 PTE；
 4. PTE 中的有效位为零，所以 MMU 触发一次异常，将 CPU 的控制传给操作系统内核中的缺页异常处理程序；
 5. 缺页处理程序确定物理内存中的牺牲页（如果该页被修改了，则把它换出到磁盘）；
 6. 缺页处理程序从磁盘理调入新页面到 高速缓存/内存 中，并更新内存中的 PTE；
 7. 缺页处理程序返回到原来的进程，再次执行导致缺页的指令，CPU 将引起缺页的虚拟地址重新发送给 MMU，现在就是页命中了，最后返回所请求的数据字给处理器；

---
## 9.6.1 结合高速缓存和虚拟内存
在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有一个问题：是使用虚拟地址还是物理地址来访问 SRAM 高速缓存。
 1. 虚拟寻址 cache（VA → cache）
	- 优点 - 可以更早访问 cache，理论上更快；
	- 缺点
		- 同义问题 -- 不同虚拟地址对应同一物理地址时，cache 中出现多个 “同一物理数据” 的副本；
		- 为消除同义问题，cache 必须理解进程、权限、页表语义；
 2. 物理寻址 cache（PA → cache） -- 大多数系统选择该种方式，原因如下：
	 - 多个进程可以把 **不同的虚拟地址** 映射到 **同一个物理页**；
	 - 保护逻辑（访问权限的检查）无需放入 cache，而是作为地址翻译过程的一部分；
	 - 以 PA 为唯一身份，不存在cache 中出现多个 “同一物理数据“ 的副本的情况；

如图 9-14 所示为一个物理寻址的高速缓存如何和虚拟内存结合起来（地址翻译发生在高速缓存查找之前），页表条目可以缓存，如同其他数据字一样：
![[NoteAboutStudy/attachments/Pasted image 20260130211257.png]]

## 9.6.2 利用 TLB 加速地址翻译
每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE，来将虚拟地址翻译为物理地址，再去访问所要访问的数据，一次 `load/store` 变成两次内存访问。为此许多系统通过在 MMU 中增加一个关于 PTE 的小的缓存，称为 **翻译后备缓冲器(Translation Lookaside Buffer，TLB)** 来试图消除这样的开销。

