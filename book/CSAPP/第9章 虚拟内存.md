---
tags:
  - CSAPP
---
一个系统中的进程是与其他进程共享 CPU 和主存资源的：
 - 随着对 CPU 需求的增长，进程就会变慢；
 - 但是如果太多的进程需要太多的内存，就会导致一些无法运行，并且一个进程误写了另一个进程使用的内存，就可能会导致错误；

为了更有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，称为 **虚拟内存(VM)**：
> VM = **硬件异常** + **硬件地址翻译** + **主存** + **磁盘文件** + **内核软件** 的交互协作
> 为 **每个进程** 提供一个大的、连续的、私有的地址空间。

虚拟内存提供了三个重要的能力：
 1. **把主存看作磁盘的高速缓存**
	- 主存只保存活动区域；
	- 磁盘保存完整地址空间；
	- 根据需要在磁盘和主存间传送数据（就不会内存不够了）；
 2. **给每个进程提供一致的地址空间**
	- 不用关心物理内存是否碎片；
	- 简化了内存管理与程序设计；
 3. **保护每个进程的地址空间不被破坏**
	- 一个进程不能访问其他的进程的内存；
	- 错误访问直接触发异常；

为什么需要理解虚拟内存：
 - 虚拟内存遍及计算机系统的所有层面，在硬件异常、汇编器、链接器、加载器、共享对象、文件和进程的设计中都扮演者重要的角色，是理解系统是如何工作的重要一环；
 - 虚拟内存使得应用程序可以，按需创建/销毁内存、把文件映射成内存、多进程共享内存、通过读写内存来读写文件；
 - 同时，每次应用程序引用一个变量、间接引用一个指针、或者调用像 `malloc/free` 这样的动态分配程序时，就会和虚拟内存发生交互。如果使用不当，就会导致错误；

本章将从 VM 如何工作 以及 程序如何使用 VM 两个部分来讲述：

---
# 9.1 物理和虚拟寻址
计算机系统的主存是一个 **由连续的字节大小的单元** 组成的数组，每个字节都有一个唯一的 **物理地址(Physical Address，PA)**。

CPU 访问内存最自然的方式就是通过物理地址，这种方式称为 **物理寻址(physical addressing)**，如图 9-1 所示为一个物理寻址的示例：
![[NoteAboutStudy/attachments/Pasted image 20260117204804.png]]
CPU 执行一条加载指令（读取从物理地址 4 处开始的 4 字节字），执行时会生成一个有效物理地址，通过内存总线传递给主存，然后主存返回数据给 CPU（CPU 会将它存放在一个寄存器中）。

现代处理器使用的是称为 **虚拟寻址(virtual addressing)** 的寻址形式，如图 9-2 所示：
![[NoteAboutStudy/attachments/Pasted image 20260117204945.png]]
CPU 通过生成一个 **虚拟地址(Virtual Address，VA)** 来访问内存，而 VA 在访问主存前会先被转换为 PA。

将一个虚拟地址转换为物理地址的过程称为 **地址翻译(address translation)**，地址翻译需要 CPU 硬件和操作系统之间的紧密合作：
 - CPU 芯片上称为 **内存管理单元(Memory Management Unit，MMU)** 硬件负责工作；
 - 利用由操作系统维护的存放在主存中的描述 VA -> PA 的映射关系的查询表来动态翻译虚拟地址；

# 9.2 地址空间
**地址空间(address space)** 是一个非负整数地址的有序集合（用于给内存字节编号的）。

如果地址空间中的整数是连续的，则称为 **线性地址空间(linear address space)**。为了简化讨论，总是假设使用的是线性地址空间。

在一个带虚拟内存的系统中，CPU 从一个有 $N=2^n$ 个地址的地址空间中生成虚拟地址，这个地址空间称为 **虚拟地址空间(virtual address space)**：{$0,1,2,……,N-1$}。

一个地址空间的大小是由最大地址所需要的位数来描述的，例如：
 - 最大虚拟地址需要 **n 位二进制数**表示
 - 地址总数是 **2ⁿ**
则称之为 $n$ 位地址空间（现代系统通常支持 32 位或者 64 位虚拟地址空间）。

**物理地址空间(physical address space)** 则对应系统中物理内存的 $M$ 个字节：{$0,1,2,……,M-1$} （M 不要求是 2 的幂，但为了简化讨论，通常还是假设 $M=2^m$）。

有了地址空间，主存中的每个字节都由一个选自 虚拟地址空间 的 VA 和 一个选自 物理地址空间 的 PA。

# 9.3 虚拟内存作为缓存的工具
从概念模型上看，虚拟内存可以被视为一个存放在磁盘上的、由 $N$ 个连续的字节大小的单元组成的数组，其中每个字节都有唯一的虚拟地址作为索引，且主存中缓存该数组中 “当前活跃” 的一部分。

和存储器层次结构中其他缓存一样，将数据分割为块，作为磁盘（较低层次）和主存（较高层次）之间的传输单元：
 - VM 系统将虚拟内存分割为大小固定的块，称为 **虚拟页(Virtual Page，VP)** ，每个的大小为 $P=2^p$ 字节；
 - 物理内存也被切割为同样大小的块，称为 **物理页(Physical Page，PP)** 或 **页帧(page frame)**，大小同样为 $P$ 字节；
VP 和 PP 一致，以确保地址翻译成立。

在任意时刻，所有虚拟页被划分为三个互斥集合：
 - **未分配** -- VM 系统尚未分配（或者创建）的页，没有数据，故不占用磁盘空间；
 - **未缓存** -- 未缓存在物理内存中的已分配页，页存在于磁盘上，但尚且不在主存中，访问时会触发缺页异常；
 - **缓存** -- 当前已缓存在物理内存中的已分配页，可直接访问；

---
## 9.3.1 DRAM 缓存的组织结构
为了清晰讲解存储层次结构中不同的缓存概念，将位于 CPU 和主存之间的 L1、L2 和 L3 高速缓存称为 SRAM 缓存，将虚拟内存系统的缓存称为 DRAM 缓存（它在主存中缓存虚拟页）。

DRAM 缓存一旦不命中，就要去访问磁盘，而访问磁盘代价极其昂贵：
 - 故 VP 通常很大，一次多搬运数据；
 - 故 缓存为全相联，即任何虚拟页都可以放置在任何物理页中；
 - 故 不命中的替换策略是操作系统使用复杂的替换算法；
 - 故 使用 ==写回==，而不是直写，避免每次写内存都要同步写磁盘，而是只发生在 DRAM ，再一次性写回；

## 9.3.2 页表
同任何缓存一样，虚拟内存系统需要一种方法来判定一个虚拟页是否缓存在 DRAM 中的某个地方：
 - 如果是，还需要知道该虚拟页存放在哪个物理页中；
 - 如果不命中，需要判断该虚拟页存放在磁盘的哪个位置，并在物理内存中选择一个牺牲页，然后将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页；
这些功能由软硬件联合提供，包括操作系统软件、MMU（内存管理单元）中的地址翻译硬件和一个存放在物理内存中称为 **页表(page table)** 的数据结构。
 - 页表将虚拟页映射到物理页；
 - 每次地址翻译硬件将一个虚拟地址转换为物理地址时，都需要读取页表；
 - 操作系统则负责维护页表内容，以及在磁盘和 DRAM 之间传送页；

如图 9-4 所示为一个页表的基本组织结构，页表就是一个 **页表条目(Page Table Entry，PTE)** 的数组，虚拟地址空间中的每个页在页表中都有一个 PTE，有多少个页就有多少个 PTE。
![[NoteAboutStudy/attachments/Pasted image 20260125195850.png]]
本节做了极度简化，假设 PTE 只有两部分：
 1. 有效位（valid bit）
	- 1：该虚拟页 **当前在 DRAM 中**
	- 0：不在 DRAM 中
 2. 地址字段
    - valid = 1：地址字段 → **物理页帧起始地址**
    - valid = 0：
        - 地址为空 → 页还没分配
        - 地址非空 → 页在磁盘上的位置

## 9.3.3 页命中
**CPU 访问的虚拟页已经在 DRAM 中**，因此**不需要触发缺页异常，不需要操作系统介入**，地址翻译由 MMU 通过页表将虚拟地址翻译为物理地址（将在 9.6 中详细描述），再直接从 DRAM 中取数据，这样称为 **页命中**。

## 9.3.4 缺页
DRAM 缓存不命中称为 **缺页(page fault)**，MMU 在检查页表项有效位时发现 0，地址翻译硬件触发缺页异常，并将控制权转交给内核的缺页异常处理程序，由操作系统来选择牺牲页，如果该牺牲页被修改过还需写回磁盘（没有就直接丢弃），然后从磁盘中复制目标页到 DRAM 中替换牺牲页，异常处理程序返回，重新执行导致缺页的指令。

| 缓存（SRAM）术语 | 虚拟内存术语         |
| ---------- | -------------- |
| 块（block）   | 页（page）        |
| 不命中（miss）  | 缺页（page fault） |
| 从下层取数据     | 页面调入（page-in）  |
| 写回下层       | 页面调出（page-out） |
| 缓存管理策略     | 页面调度策略         |

当有不命中发生时，才换入页面的策略称为 **按需页面调度(demand paging)** (现代通用操作系统都使用使用按需分页)。

## 9.3.5 分配页面
如图 9-8 所示为操作系统分配一个新的虚拟内存页时对页表的影响：
![[NoteAboutStudy/attachments/Pasted image 20260125204832.png]]
分配一个虚拟页时，操作系统只是在磁盘上为它分配空间，并更新页表，并不会立刻把它放进 DRAM。

## 9.3.6 局部性在虚拟内存中
尽管在整个运行过程中程序引用的不同的页面的总数可能超出物理内存总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的 **活动页面(active page)** 集合上工作，这个集合称为 **工作集(working set)** 或者 **常驻集合(resident set)**。在第一次访问时，将工作集调度到内存中之后，后续的访问几乎都是页命中，不会产生额外的磁盘流量，也就会提升虚拟内存的性能。

但是当 工作集的大小超出了物理内存的大小，就会导致 **抖动(thrasing)**，页面将不断地换进换出（如果一个程序性能很慢，就要考虑是不是这种情况了）。

# 9.4 虚拟内存作为内存管理的工具
在前面都说的是有一个单独的页表，将一个虚拟地址空间映射到物理地址空间，实际上，操作系统为每个进程提供了一个独立的页表，也就是一个独立的虚拟地址空间，同一个虚拟地址，在不同进程中可以映射到**完全不同的物理页**，如图 9-9 所示：
![[NoteAboutStudy/attachments/Pasted image 20260126205026.png]]
多个虚拟页面可以映射到同一个共享物理页面上。

VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配：
 - **简化链接**。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的位置，这样的一致性简化了链接器的设计和实现；
 - **简化加载**。
	1. 当要把目标文件中 `.text` 和 `.data` 节加载到一个新创建的进程中，Linux 加载器为代码和数据分配虚拟页，并标记为 **未缓存** 的，把 PTE 指向磁盘文件中的位置，并没有把代码或数据复制到内存中；
	2. 在每个页被初次引用时，要么是 CPU 取指令时执行，要么是正在执行的指令访问某个数据地址，按需调度；
	3. 将一组连续的虚拟页映射到文件的某个位置，称为 **内存映射(memory mapping)**，Linux 提供称为 `mmap` 的系统调用，允许用户程序自己做内存映射（将在 9.8 中描述应用级内存映射）；
 - **简化共享**。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，不与其他进程共享，然而在一些情况中，需要进程共享代码和数据，此时操作系统将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本；
 - **简化内存分配**。当一个运行在用户进程中的程序要求额外的堆空间时，操作系统分配 $k$ 个连续的虚拟页，并将它们映射到物理内存中任意位置的 $k$ 个物理页，且这些物理页不需要连续；

# 9.5 虚拟内存作为内存保护的工具
任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问：
 - 不应该允许一个用户进程修改它的只读代码段；
 - 不应该允许它读或修改任何内核中的代码和数据结构；
 - 不应该允许它读或者写其他进程的私有内存；
 - 不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）；

因为每次 CPU 生成一个地址时，地址翻译硬件都会读 PTE，所以通过在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问，如图 9-10 所示：
![[NoteAboutStudy/attachments/Pasted image 20260126225817.png]]
在这个示例中，每个 PTE 中添加了三个许可位：
 - SUP 位表示进程是否必须运行在内核（超级用户）模式下才能访问该页（运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 0 的页面）；
 - READ 位和 WRITE 位控制对页面的读和写访问；

如果一条指令违反了这些许可条件，那么 CPU 就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。Linux shell 一般将这种异常报告为“段错误（segmentation fault）”。

# 9.6 地址翻译
该节主要讲述地址翻译的基础知识，以了解硬件在支持虚拟内存中的角色，但是省略了大量细节，包括时序相关的细节（这部分细节对硬件设计来说是非常重要的，但超出本书讨论范围）。

如图 9-11 概括了在本节中将要使用的所有符号：
![[NoteAboutStudy/attachments/Pasted image 20260130201859.png]]

形式上来说，地址翻译是一个 $N$ 元素的虚拟地址空间(VAS) 中的元素和一个 $M$ 元素的物理地址空间(PAS) 中的元素之间的映射 -- $MAP:VAS→PAS∪∅$，含义：
 - 虚拟地址 **要么** 映射到某个物理地址；
 - **要么** 当前不在物理内存中（Ø → 缺页）；

如图 9-12 所示为 MMU 如何利用页表来实现映射：
![[NoteAboutStudy/attachments/Pasted image 20260130202707.png]]
CPU 中的一个控制寄存器 -- **页表基址寄存器(Page Table Base Register，PTBR)** 指向当前进程页表的起始地址。$n$ 位的虚拟地址包含两个部分：
 - 一个 $p$ 位的 **虚拟页面偏移(Virtual Page Offset，VPO)**；
 - 一个 $(n-p)$ 位的 **虚拟页号(Virtual Page Number，VPN)**；
MMU 利用 VPN 来选择适当的 PTE。将页表条目中 **物理页号(Physical Page Number，PPN)** 和虚拟地址中的 VPO 串联起来，就得到相对应的物理地址。同时，因为物理和虚拟页面都是 $P$ 字节的，所以 **物理页面偏移(Physical Page Offset，PPO)** 和 VPO 是相同的。

如图 9-13a 展示了当页面命中时，CPU 硬件执行的步骤（页命中完全是由硬件来处理的）：
	![[NoteAboutStudy/attachments/Pasted image 20260130203610.png]]
 1. 处理器生成一个虚拟地址，并传送给 MMU；
 2. MMU 生成 PTE 地址（PTEA），并从 高速缓存/内存 请求适当的 PTE；
 3. 高速缓存/内存 向 MMU 返回 PTE；
 4. MMU 构造物理地址 PA 传送给 高速缓存/内存；
 5. 高速缓存/内存 返回所请求的数据字给处理器；

如图 9-13b 展示了处理缺页时硬件和操作系统协作完成的步骤：
	![[NoteAboutStudy/attachments/Pasted image 20260130204356.png]]
 1. 处理器生成一个虚拟地址，并传送给 MMU；
 2. MMU 生成 PTE 地址（PTEA），并从 高速缓存/内存 请求适当的 PTE；
 3. 高速缓存/内存 向 MMU 返回 PTE；
 4. PTE 中的有效位为零，所以 MMU 触发一次异常，将 CPU 的控制传给操作系统内核中的缺页异常处理程序；
 5. 缺页处理程序确定物理内存中的牺牲页（如果该页被修改了，则把它换出到磁盘）；
 6. 缺页处理程序从磁盘理调入新页面到 高速缓存/内存 中，并更新内存中的 PTE；
 7. 缺页处理程序返回到原来的进程，再次执行导致缺页的指令，CPU 将引起缺页的虚拟地址重新发送给 MMU，现在就是页命中了，最后返回所请求的数据字给处理器；

---
## 9.6.1 结合高速缓存和虚拟内存
在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有一个问题：是使用虚拟地址还是物理地址来访问 SRAM 高速缓存。
 1. 虚拟寻址 cache（VA → cache）
	- 优点 - 可以更早访问 cache，理论上更快；
	- 缺点
		- 同义问题 -- 不同虚拟地址对应同一物理地址时，cache 中出现多个 “同一物理数据” 的副本；
		- 为消除同义问题，cache 必须理解进程、权限、页表语义；
 2. 物理寻址 cache（PA → cache） -- 大多数系统选择该种方式，原因如下：
	 - 多个进程可以把 **不同的虚拟地址** 映射到 **同一个物理页**；
	 - 保护逻辑（访问权限的检查）无需放入 cache，而是作为地址翻译过程的一部分；
	 - 以 PA 为唯一身份，不存在cache 中出现多个 “同一物理数据“ 的副本的情况；

如图 9-14 所示为一个物理寻址的高速缓存如何和虚拟内存结合起来（地址翻译发生在高速缓存查找之前），页表条目可以缓存，如同其他数据字一样：
![[NoteAboutStudy/attachments/Pasted image 20260130211257.png]]

## 9.6.2 利用 TLB 加速地址翻译
每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE，来将虚拟地址翻译为物理地址，再去访问所要访问的数据，一次 `load/store` 变成两次内存访问。为此许多系统通过在 MMU 中增加一个关于 PTE 的小的缓存，称为 **翻译后备缓冲器(Translation Lookaside Buffer，TLB)** 来试图消除这样的开销。

TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块，TLB 通常高度相联，如图 9-15 所示：
![[NoteAboutStudy/attachments/Pasted image 20260130212439.png]]
用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号（VPN）中提取出来的，只缓存映射关系。如果 TLB 有 $T=2^t$ 个组，那么 **TLB 索引(TLBI)** 是由 VPN 的 $t$ 个最低位组成的，而 **TLB 标记(TLBT)** 是由 VPN 中剩余的位组成的。

如图 9-16 分别展示了 TLB 命中与不命中的步骤，前者所有的地址翻译步骤都是在芯片上的 MMU 中执行的（超快），后者 MMU 需要从 L1 缓存中取出对应的 PTE 存放在 TLB 中（可能会覆盖一个已经存在的条目）：
![[NoteAboutStudy/attachments/Pasted image 20260130213134.png]]

## 9.6.3 多级页表
对于一个 32 位的地址空间、4KB 的页面和一个 4 字节的 PTE，即使应用所引用的只是虚拟地址空间中很小的一部分，也总是需要一个 4 MB 的页表驻留在内存中，若是对于一个 64 位的系统，将更复杂。而用来压缩页表的常用方法是使用层次结构的页表，即 **多级页表(Hierarchical Page Table)**。

如图 9-17 展示了在 32 位虚拟地址空间（依旧是 4KB 的页面和 4 字节的 PTE，并且内存的前 2K 个页面分配给了代码和数据、接下来 6K 个页面未分配、再接下来 1023 个页面同样未分配、接下来 1 个页面分配给用户栈）中构造一个两级的页表层次结构：
 ![[NoteAboutStudy/attachments/Pasted image 20260131193834.png]] 
  - 一级页表中的每个 PTE 负责映射虚拟地址空间中一个 4MB 的 **片(chunk)**，每一片都是由 1024 个连续的页面组成的：
	  - 如果片 $i$ 中的每个页面都未被分配，那么一级页表的 PTE $i$ 就为空；
	  - 如果片 $i$ 中至少有一个页分配了，那么一级页表的 PTE $i$ 就指向一个二级页表的基址；
  - 二级页表中的每个 PTE 都负责映射一个 4KB 的虚拟内存页面，与 “传统一级页表” 一样（使用 4 字节的 PTE，每个一级和二级页表都是 4KB 字节，与一个页面大小一样）。
这种方法从两个方面节省了空间：
 - 如果一级页表中的一个 PTE 是空的，那么对应的二级页表就不存在，这是最大的节省来源；
 - 只有一级页表需要常驻内存，虚拟内存系统可以在需要时创建、页面调入或调出二级页面，且最经常使用的二级页表才需要缓存在内存中；

如图 9-18 描述了使用 $k$ 级页表层次结构的地址翻译：
![[NoteAboutStudy/attachments/Pasted image 20260131195803.png]]
虚拟地址被划分为 $k$ 个 VPN 和 1 个 VPO：
 - 每个 VPN $i$ 都是到 第 $i$ 级页表的索引，其中 $1≤i≤k$；
 - 第 $j$ 级页表中的每个 PTE，都指向第 $j+1$ 级的某个页表的基址，其中 $1≤j≤k-1$；
 - 第 $k$ 级页表中的每个 PTE 包含某个物理页的 PPN（或是一个磁盘块的地址）；
 - 为了翻译为物理地址，在能够确定 PPN 之前，MMU 需要访问 $k$ 个PTE，找到最终 PTE；
 - 对于只有一级的页表结构，PPO 和 VPO 是相同的；
而访问 $k$ 个 PTE，尽管看起来要很缓慢，但是 TLB 通过将不同层次上页表的 PTE 缓存起来，所以其实并不是很缓慢。

## 9.6.4 综合：端到端的地址翻译
本节通过具体的地址翻译示例来综合 9.6 节内容（p573）

一次内存访问遵循固定顺序：虚拟地址 → TLB（地址翻译缓存）→ 页表（TLB 未命中时）→ 翻译成物理地址 → L1 数据缓存 → 主存（必要时）
- 虚拟地址 = VPN + VPO
- TLB 使用 VPN（TLBI + TLBT）进行虚拟寻址
- 物理地址 = PPN + PPO（PPO = VPO）
- Cache 使用物理地址（CT + CI + CO）进行查找（CT - 标记，CI - 组索引，CO - 块偏移）

其他情况：
- **TLB 不命中，PTE 有效**  → 访问页表，填充 TLB，继续执行
- **PTE 无效（缺页）**  → 触发缺页异常，由内核调页并重新执行指令
- **Cache 不命中**  → 访问主存获取数据

# 9.7 案例研究：`Intel Core i7/Linux` 内存系统
本节通过一个实际系统的案例研究来总结对虚拟内存的讨论：运行 `Linux` 系统的 `Intel Core i7`，理论支持 64 位虚拟 / 物理地址空间，实际实现为 48 位的虚拟地址空间（256 TB）和 52 位的物理地址空间（4 PB），同时兼容 32 位模式（4 GB）的虚拟和物理地址空间。

如图 9-21 所示为 Core i7 内存系统的重要部分：
 ![[NoteAboutStudy/attachments/Pasted image 20260131213502.png]]
 - 处理器封装包括四个核、一个所有核共享的 L3 高速缓存以及一个 DDR3 存储控制器；
 - 每个核包含一个层次结构的 TLB、一个层次结构的数据和指令的高速缓存，以及一组快速的点到点链路（这种链路基于 QuickPath 技术，为了让一个核与其他核以及外部 I/O 桥直接通信）；
 - TLB 为虚拟寻址，且四路组相联；
 - L1、L2 和 L3 高速缓存为物理寻址，块大小为 64 字节，L1 和 L2 是 8 路组相联，L3 为 16 路组相联；
 - 页大小可以在启动时被配置为 4KB 或 4MB（`Linux` 使用的是 4KB 的页）；

---
## 9.7.1 `Core i7` 地址翻译
如图 9-22 总结了完整的 `Core i7` 地址翻译过程，从 CPU 产生虚拟地址的时刻一直到来自内存的数据字到达 CPU：
 ![[NoteAboutStudy/attachments/Pasted image 20260201205108.png]]
 - `Core i7` 采用四级页表层次结构，且每个进程都有自己的页表层次结构；
 - 当一个进程在运行时，Core i7 体系结构允许页表换进换出，但是内存中还是驻留着与已分配的页相关联的页表；
 - CR3 控制寄存器指向第一级页表（L1）的起始位置，CR3 的值是每个进程上下文的一部分，所以每次上下文切换时，CR3 的值都需要恢复；

如图 9-23 所示为第一级、第二级或第三级页表中条目的格式：
 ![[NoteAboutStudy/attachments/Pasted image 20260204154657.png]]
当 P = 1时，地址字段包含一个 40 位物理页号(PPN)，指向下一级页表的物理地址的基址（意味着要求物理页 和 页表 4KB 对齐）。

如图 9-24 所示为第四级页表中条目的格式：
 ![[NoteAboutStudy/attachments/Pasted image 20260204155105.png]]
当 P = 1时，地址字段包含一个 40 位物理页号(PPN)，指向物理内存中的某一页的基址（要求物理页 和 页表 4KB 对齐）。

PTE 有三个权限位，控制对页的访问：
 - R/W 位确定页的内容是只读还是可写的；
 - U/S 位确定是否能够在用户模式中访问该页（用户态还是内核态）；
 - XD(禁止执行) 位是在 64 位系统中引入的，可用来禁止从某些内存页取指令（通过限制只能执行只读代码段，使得操作系统内核降低了缓冲区溢出攻击的风险）；

当 MMU 翻译每一个虚拟地址时，还会更新两个内核缺页处理程序会用到的位：
 - 每次访问一个页时，MMU 都会设置 A 位，称为 **引用位(reference bit)**，内核通过该位来实现页替换算法；
 - 每次对一个页进行写入之后，MMU 都会设置 D 位。称为 **修改位** 或 **脏位(dirty bit)**，修改位决定内核在复制替换页之前是否需要写回牺牲页；
内核可以通过调用一条特殊的内核模式指令来清除引用位或修改位。

如图9-25 为 `Core i7` MMU 如何使用四级页表来将虚拟地址翻译成物理地址：
 ![[NoteAboutStudy/attachments/Pasted image 20260204160628.png]]
 1. CPU 生成虚拟地址
 2. MMU 从 CR3 找到 L1 页表地址（CR3 寄存器中包含 L1 页表的物理地址）
 3. 用 VPN1 索引 L1 → 得到 L2 地址
 4. 用 VPN2 索引 L2 → 得到 L3 地址
 5. 用 VPN3 索引 L3 → 得到 L4 地址            
 6. 用 VPN4 索引 L4 → 得到 PPN
 7. PPN + VPO → 物理地址
   ⚠️ 如果某一级 PTE 无效 → **缺页异常**
   
 Core i7（48 位 VA，4KB 页）中：
- **VPO**：12 位（页内偏移）；
- **VPN**：36 位，被拆成 **4 × 9 位**；

这 4 个 VPN 片段分别索引：

|层级|Linux 名称|作用|
|---|---|---|
|L1|PGD|指向 L2 页表|
|L2|PUD|指向 L3 页表|
|L3|PMD|指向 L4 页表|
|L4|PTE|指向物理页|

> [!tip]+ 优化地址翻译
> 对地址翻译的讨论中，描述了一个顺序的两个步骤的过程：
>  1. MMU 将虚拟地址翻译成物理地址；
>  2. 将物理地址传送到 L1 高速缓存。
>  
> 然而，实际的硬件实现使用了一个灵活的技巧，允许这些步骤部分重叠，因此也就加速了对 L1 高速缓存的访问。
> 
> 例如，页面大小为 4KB 的 Corei7 系统上的一个虚拟地址有 12 位的 VPO，并且这些位和相应物理地址中的 PPO 的 12 位是相同的。因为八路组相联的、物理寻址的 L1 高速缓存有 64 个组和大小为 64 字节的缓存块，每个物理地址有 6 个（$log_264$）缓存偏移位和 6 个（$log_264$）索引位。这 12 位恰好符合虚拟地址的 VPO 部分，L1 Cache 查找所需的全部索引信息（Index + Offset）正好落在 $VPO$ 的 12 位之内。这意味着 **Cache 索引不需要等待 MMU 的翻译结果，直接用虚拟地址的低 12 位就能确定在哪个“组”里**。
> 
> 当 CPU 需要翻译一个虚拟地址时，它就发送 VPN 到 MMU，发送 VPO 到高速 L1 缓存。当 MMU 向 TLB 请求一个页表条目时，L1 高速缓存正忙着利用 VPO 位查找相应的组，并读出这个组里的 8 个标记和相应的数据字。当 MMU 从 TLB 得到 PPN 时，缓存已经准备好试着把这个 PPN 与这 8 个标记中的一个进行匹配了。

## 9.7.2 Linux 虚拟内存系统
一个虚拟内存系统要求硬件和内核软件之间的紧密协作，但是版本与版本之间的细节不尽相同，为此本节只对 Linux 的虚拟内存系统做一个描述，关于一个实际的操作系统是如何组织虚拟内存，以及如何处理缺页。

---
如图 9-26 所示，Linux 为每个进程维护了一个单独的 **虚拟地址空间**：
![[NoteAboutStudy/attachments/Pasted image 20260204164439.png]]
内核虚拟内存位于用户栈之上，包含内核中的代码和数据结构：
 - 内核虚拟内存的某些区域被映射到所有进程共享的物理页面，例如将一段连续的虚拟页面映射到相应的一组连续的物理页面，以便内核访问物理内存中的任何位置；
 - 内核虚拟内存的其他区域包含每个进程都不相同的数据；

### 1. Linux 虚拟内存区域（VMA）
Linux 将虚拟内存组织成一些 **区域**（也叫作**段**）的集合，一个区域就是已分配的虚拟内存的连续 **片**，这些片中的页面是以某种方式相关联的，每个存在的虚拟页都保存在某个区域中，不属于某个区域的虚拟页是无效的且不能被进程引用。区域的概念允许虚拟地址空间有间隙 -- 即内核不用记录那些间隙（不存在的虚拟页），完全不占用内存、磁盘或页表资源，仅通过 VMA 边界间接表示其不存在性。

如图 9-27 所示为一个进程中虚拟内存区域的内核数据结构：
 ![[NoteAboutStudy/attachments/Pasted image 20260204170522.png]]
 - 内核为系统中的每个进程维护一个单独的任务结构 `task_struct`，任务结构中的元素包含或者指向内核运行该进程所需要的所有信息；
	 - 任务结构中的一个条目指向 `mm_struct`，描述了虚拟内存的当前状态，其中有两个字段：
		 - `pgd`，指向第一级页表的基址（页表根），当内核运行这个进程时，就将 `pgd` 存放在 CR3 控制寄存器中（给 MMU 使用）；
		 - `mmap`，指向一个 `vm_area_structs`（区域结构）的链表，其中每个 `vm_area_structs` 都描述了当前虚拟地址空间的一个区域，一个具体区域的区域结构包含下面的字段：
			 - `vm_start`，指向这个区域的起始处；
			 - `vm_end`，指向这个区域的结束处；
			 - `vm_prot`，描述这个区域内包含的所有页的读写许可权限；
			 - `vm_flags`，描述这个区域内的页面是与其他进程共享的，还是私有的（还有其他的一些信息）；
			 - `vm_next`，指向链表中的下一个区域结构；

### 2. Linux 缺页异常处理
当 MMU 在试图翻译某个虚拟地址 A 时，触发缺页，控制权转移到内核的缺页处理程序，处理程序随后执行以下步骤：
 1. 虚拟地址 A 是否合法 -- 是否在某个区域结构定义的区域内
	- 缺页处理程序搜索区域结构的链表，在每个区域结构中查找 `vm_start ≤ A < vm_end`（Linux 在链表中构建了一棵树，并在树上进行查找）；
	- 找不到就触发一个 **段错误**，从而终止这个进程（这个情况在图 9-28 中标识为 “1”）；
2. 访问是否合法 -- 进程是否有读、写或者执行这个区域内页面的权限
	- 检查 VMA 的 `vm_prot`、当前访问类型（读 / 写 / 执行）、当前 CPU 特权级（用户 / 内核）；
	- 如果不合法则触发保护异常，从而终止这个进程（这种情况在图 9-28 中标识为 “2”）；
3. 地址合法、访问合法、页不在内存中，找物理页（必要时选牺牲页），若脏页 → 写回磁盘，把新页调入内存并更新页表项，返回用户态，**重新执行那条指令**

![[NoteAboutStudy/attachments/Pasted image 20260204175842.png]]

# 9.8 内存映射
Linux 通过**内存映射(memory mapping)** 将虚拟内存区域(VMA) 与磁盘上的某个**对象**关联，用于初始化该区域中的虚拟页面。虚拟内存区域可映射到两类对象之一：
 1. **Linux 文件系统中的普通文件**
	- 一个区域可以映射到一个普通磁盘文件的某一连续部分；
	- 文件区被分成页大小的片，每一片包含一个虚拟页面的初始内容；
	- 页面按需调度，CPU 首次访问时才调入物理内存中；
	- 若映射区域大于文件区，则末尾部分用零来填充；
 2. **匿名文件**
	- 区域映射到一个由内核创建的、内容全是二进制零的匿名文件；
	- CPU 首次访问时，内核会在物理内存中选择牺牲页并替换为二进制零的页面更新页表（如果牺牲页修改过则需写回磁盘），不涉及磁盘读入，也成为 **请求二进制零的页(demand-zero page)**；
无论是以上哪种，当一个虚拟页面被初始化了，就需要在一个由内核维护的专门的 **交换文件(swap file)** （也称 **交换空间** 或 **交换区域**）之间换入换出，因此，交换空间限制着当前运行的进程能够分配的虚拟页面总数。

---
## 9.8.1 再看共享对象
为每个进程提供自己私有的虚拟地址空间，从而免受其他进程的读写错误。但是，许多进程有同样的只读或常用代码区域，如果每个进程都在物理内存中保存这些代码的副本，就会很浪费。而内存映射提供了一个机制，用来控制多个进程共享对象。

一个对象可以被映射到虚拟内存的一个区域：
 - 要么是 **共享对象**，对于一个将该共享对象映射到进程的虚拟地址空间的进程，该进程任何写操作，对于其他也把该共享对象映射到进程的虚拟地址空间的进程是可见的，同时也会写回磁盘，该虚拟内存区域称为 **共享区域**；
 - 要么是 **私有对象**，对于一个映射到私有对象的区域，所作出的改变，对于其他进程来说是不可见的，同时也不会写回磁盘，该虚拟内存区域称为 **私有区域**；

假设进程 1 将一个共享对象映射到它的虚拟内存的一个区域中，如图 9-29a 所示。现在假设进程 2 将同一个共享对象映射到它的地址空间（并不一定要和进程 1 在相同的虚拟地址处，如图 9-29b 所示）：
![[NoteAboutStudy/attachments/Pasted image 20260206214514.png]]
内核通过文件名识别这是同一个对象，直接让两个进程页表指向同一物理页。

私有对象通过 **写时复制(copy-on-write)** 映射到虚拟内存中，一个私有对象开始生命周期的方式基本于共享对象一样，在物理内存中只保存私有对象的一份副本，如图 9-30a 所示为一种情况，两个进程映射私有对象，但是共享这个对象同一个物理副本，相应私有区域的页表被标记为 **只读**，区域结构被标记为 **私有的写时复制**。只要没有进程试图写这个私有区域，它们就可以继续共享这一单独副本。
![[NoteAboutStudy/attachments/Pasted image 20260206214959.png]]
但是，只要由一个进程试图写这个私有区域的某个页面，那么就会触发保护故障。当故障处理程序分析保护异常是由于进程试图写私有的写时复制区域的页面引起的，就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新副本，然后恢复可写权限（如图 9-30b 所示）。当故障处理程序返回时重新执行写操作，就可以在新创建的页面上正常执行了。通过延迟复制，按需复制，最大化节省物理内存。

## 9.8.2 再看 `fork` 函数
 `fork` 函数是如何创建一个带有自己独立虚拟地址空间的新进程的：
  - 当 `fork` 函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的 PID。为了给这个新进程创建虚拟内存，它创建了当前进程的 `mm_struct`、区域结构和页表的原样副本。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制；
  - 当 `fork` 在新进程中返回时，新进程现在的虚拟内存刚好和调用 `fork` 时存在的虚拟内存相同。当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，这样就为每个进程保持了私有虚拟地址空间，同时也节省了物理内存。

## 9.8.3 再看 `execve` 函数
假设运行在当前进程中的程序执行了这样的 `execve` 调用：`execve("a.out", NULL, NULL);` ，如 [[NoteAboutStudy/book/CSAPP/第8章 异常控制流|第8章 异常控制流]] 中所讲述的，`execve` 函数在当前进程中加载并运行包含在可执行目标文件 `a.out` 中的程序，用 `a.out` 程序替代了当前程序。

加载并运行 `a.out` 需要以下几个步骤：
 - **删除已存在的用户区域**，删除当前进程虚拟地址的 ==用户部分== 中已存在的区域结构；
 - **映射私有区域**，为新程序的代码、数据、`bss` 和栈区域创建新的区域结构（使用 `mmap`），所有这些都是私有区域、写时复制的，如图 9-31 概括了私有区域的不同映射
	 - 代码和数据区域被映射为 `a.out` 文件中的 `.text` 和 `.data` 区；
	 - `bss` 区域是请求二进制零的，映射到匿名文件，其大小包含在 `a.out` 中；
	 - 栈和堆区域都是请求二进制零的，初始长度为零；
- **映射共享区域**，如果 `a.out` 程序与共享对象链接，那么这些对象都是动态链接到这个程序，然后再映射到用户虚拟地址空间中的共享区域内；
- **设置程序计数器(PC)**，`execve` 最后设置当前进程上下文中的程序计数器，使之指向代码区域的入口，下次调度该进程时，从这个入口开始执行，Linux 将根据需要换入代码和数据页面（之前只是映射了，并没有调入）；
![[NoteAboutStudy/attachments/Pasted image 20260207204403.png]]

## 9.8.4 使用 `mmap` 函数的用户级内存映射
Linux 进程可以使用 `mmap` 函数来创建新的虚拟内存区域，并将对象映射到这些区域中：
```c
#include <unistd.h>
#include <sys/mman.h>
void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);    // 若成功返回指向映射区域的指针，若出错返回 MAP_FAILED(-1)
```
`mmap` 函数要求内核创建一个新的虚拟内存区域，最好是从地址 `start` 开始的一个区域（通常被定义为 NULL，表示内核寻找合适的地址），并将文件描述符 `fd` 指定的对象的一个连续的片映射到这个区域，该片的大小为 `length` 字节，从距该文件开始处偏移量为 `offset` 字节的地方开始，如图 9-32 描述了这些参数的意义：
![[NoteAboutStudy/attachments/Pasted image 20260207205720.png]]

参数 `prot` 包含描述新映射的虚拟内存的访问权限位（即相应区域结构中的 `vm_prot` 位）：
 - PROT_EXEC，这个区域的页面可以被 CPU 执行的指令组成；
 - PROT_READ，这个区域内的页面可读；
 - PROT_WRITE，可写；
 - PROT_NONE，禁止访问；

参数 `flags` 由描述被映射对象类型的位组成：
 - MAP_ANON，则被映射对象为匿名对象，相应的虚拟页面是请求二进制零的；
 - MAP_PRIVATE，表示被映射对象是一个私有对象，写时复制；
 - MAP_SHARED，表示是一个共享对象；

---
`munmap` 函数删除虚拟内存的区域：
```c
#include <unistd.h>
#include <sys/mman.h>
int munmap(void *start, size_t length);    //成功则返回 0，出错返回 -1
```
`munmap` 函数删除从虚拟地址 `start` 开始，删除接下来 `length` 字节组成的区域，后续如引用已删除区域则会导致段错误；

# 9.9 动态内存分配
为了使申请/释放虚拟内存更方便，以及拥有更好的可移植性，于是产生了 **动态内存分配器(dynamic memory allocator)**。

动态内存分配器负责维护一个进程的虚拟内存区域，称为 **堆(heap)** -- 此处的堆与数据结构中的 [[NoteAboutStudy/Data Structures and  Algorithms/树/堆|堆]] 不同，如图 9-33 所示：
 ![[NoteAboutStudy/attachments/Pasted image 20260213192245.png]]
 - 初始内容全为 0（匿名映射）；
 - 紧跟在未初始化的数据区域后；
 - 向高地址增长；
 - 对于每个进程，内核通过维护一个指针 `brk` ，指向堆顶；

分配器将堆视为一组不同大小的 **块** 的集合，每个块都是一段连续的虚拟内存片：
 - 要么是 **已分配** 的，显式地保留以供应用程序使用，保持已分配状态直到被释放（要么是应用程序显式执行，要么是内存分配器自身隐式执行）；
 - 要么是 **空闲** 的，保持空闲直到显式地被应用分配；

分配器有两种基本风格，两种风格都要求应用显式地分配块，不同之处在于由哪个实体来负责释放已分配的块：
 - **显式分配器(explicit allocator)**，要求应用显式地释放任何已分配的块
	 - C 程序通过调用 `malloc` 函数来分配，`free` 函数来释放；
	 - C++ 中则通过 `new` 和 `delete`；
 - **隐式分配器(implicit allocator)**，要求分配器检测一个已分配块何时不再被程序所使用，此时释放这个块（也称 **垃圾收集器 garbage collector**，而自动释放未使用的已分配的块的过程称为 **垃圾收集**）
	 - Java、Python、Lisp、ML 等高级语言依赖垃圾收集来释放已分配的块；

内存分配不仅存在于操作系统 -- 管理堆内存的分配器，也可以出现在各种上下文中，例如：游戏引擎、浏览器、图形软件、数据库，都会：
 1. 先申请一大块堆；
 2. 再自己实现小型分配器；

---
## 9.9.1 `malloc` 函数和 `free` 函数
C 标准库提供了一个称为 `malloc` 程序包的显式分配器。

### `malloc` 向堆申请一块内存
程序通过调用 `malloc` 函数来从堆中分配块：
```C
#include <stdlib.h>
void *malloc(size_t size);    // 若成功返回已分配块的指针，出错返回 NULL
```
向堆申请一块至少为 `size` 字节的连续虚拟内存的块，并返回指向起始地址的指针：
 - 返回的是 `void*`，`malloc` 不关心类型；
 - `malloc` 保证与可能包含在这个块内的任何数据对象类型对齐 -- 即保证可以存放任何类型
	 - 32 位程序，8 字节对齐；
	 - 64 位程序，16 字节对齐；
- `malloc` 不会初始化内存，可通过 `calloc` 函数将分配的内存初始化为零；
- 想要改变一个以前已分配的块的大小，可以使用 `realloc` 函数；
- 如果出错，则返回 NULL，并设置 `error`；

`malloc` 通过 `mmap` 和 `munmap` 函数来显式地分配和释放堆内存，或者还可以使用 `sbrk` 函数（`malloc` 只是管理者）：
```c
#include <unistd.h>
void *sbrk(intptr_t incr);    // 成功返回旧的 brk 指针，出错则返回 -1
```
`sbrk` 函数通过将内核的 `brk` 指针增加 `incr` 来扩展和收缩堆：
 - 如果成功，返回 `brk` 的旧值；
 - 如果出错，返回 -1，并将 `error` 设置为 ENOMEM；
 - 如果 `incr` 为零，那么旧返回 `brk` 的当前值（用一个负的 `incr` 来调用 `sbrk` 是合法的，返回 指向新堆顶向上 `abs(incr)` 字节处）；

### `free` 把块还给分配器
程序通过调用 `free` 函数来释放已分配的堆块：
```c
#include <stdlib.h>
void free(void *ptr);    // 无返回值
```
`free` 之后，这块内存变成 **空闲块**，可能被下一次 `malloc` 使用。

`ptr` 参数必须指向一个从 `malloc`、`calloc` 或者 `realloc` 获得的已分配的块的起始位置，如果不是，那么 `free` 的行为就是未定义的，且由于不返回，就会导致一些运行时错误（将在 9.11 中看到）。

### 具体实现
如图 9-34 展示了一个 `malloc` 和 `free` 的实现是任何管理一个 C 程序的 16 字的小堆：
 ![[NoteAboutStudy/attachments/Pasted image 20260213203508.png]]
 每个方框代表了一个 4 字节的字，初始时，堆是由一个大小为 16 个字的、双字对齐的、空闲块组成的：
  * 图 9-34a：程序请求一个 4 字的块。`malloc` 的响应是：从空闲块的前部切出一个 4 字的块，并返回一个指向这个块的第一字的指针；
  * 图 9-34b：程序请求一个 5 字的块。`malloc` 的响应是：从空闲块的前部分配一个 6 字的块。在本例中，`malloc` 在块里填充了一个额外的字，是为了保持空闲块是双字边界对齐的；
  * 图 9-34c：程序请求一个 6 字的块，而 `malloc `就从空闲块的前部切出一个 6 字的块； 
  * 图 9-34d：程序释放在图 9-34b 中分配的那个 6 字的块。注意，在调用 `free` 返回之后，指针 `p2` 仍然指向被释放了的块。应用有责任在它被一个新的 `malloc` 调用重新初始化之前，不再使用 `p2`；
  * 图 9-34e：程序请求一个 2 字的块。在这种情况中，`malloc` 分配在前一步中被释放了的块的一部分，并返回一个指向这个新块的指针。

## 9.9.2 为什么要使用动态内存分配
经常是直到程序实际运行时，才知道某些数据结构的大小，但是编译时需要决定数据的大小，所以可以通过动态内存分配在运行时再来决定大小。

动态内存不仅解决 “大小未知”，还解决 **生命周期未知**，例如栈内存有严格生命周期，函数返回 → 自动销毁，但很多数据需要跨函数存在：链表、树、图、哈希表、缓存、对象系统。而动态内存分配使得这些数据结构可以在任何函数内创建，在任意时间释放。

但是不正确使用动态分配会导致一些错误，如内存泄漏、野指针，将在 9.11 中讨论这一内容。

## 9.9.3 分配器的要求和目标
显式分配器必须在一些相当严格的约束条件下工作：
 - **处理任意请求序列**，一个应用可以有任意的分配请求和释放请求序列，只要满足约束条件，是完全随机的顺序，不保证分配与释放成对出现或者嵌套；
 - **立即响应请求**，分配器必须立即响应分配请求，不允许分配器为了提高性能重新排列或者缓冲请求；
 - **只使用堆**，为了使分配器可扩展，所使用的任何数据结构都必须保存在堆里；
 - **对齐要求**，必须对齐块，使得可以存放任何类型的数据对象；
 - **不修改已分配的块**，只能操作或者改变空闲块；

在这些约束条件下，为了实现吞吐率最大化和内存使用率最大化（两个目标通常是相互冲突的）：
 - **最大化吞吐率**，吞吐率为每个单位时间内完成的请求数，可以通过使满足分配的释放请求的平均时间最小化来使吞吐率最大化，而一个分配请求的最坏运行时间与空闲块的数量成线性关系，一个释放请求的运行时间是个常数；
 - **最大化内存使用率**，通过 **峰值利用率(peak utilization)** 来描述一个分配器使用堆的效率
	 - 如果给定 $n$ 个分配和释放请求的某种顺序 $R_0,R_1,…,R_k,…,R_{n-1}$；
	 - 如果一个应用程序请求一个 $p$ 字节的块，那么得到的 **有效载荷(payload)** 是 $p$ 字节，在请求 $R_k$ 完成后，**聚集有效载荷(aggregate payload)** 表示为 $P_k$，为当前已分配的块的有效载荷之和，而 $H_k$ 表示堆当前的大小；
	 - 那么，前 $k+1$ 个请求的 **峰值利用率** $U_k=\frac{max_{i≤k}P_i}{H_k}$；

`malloc` 设计的本质是：**在速度和空间之间找平衡**

## 9.9.4 碎片
造成堆利用率很低的主要原因是 **碎片(fragmentation)** 的现象，当虽然有未使用的内存但却不能用来满足分配请求时，就会有这种现象。有两种形式的碎片：
 - **内部碎片(internal fragmentation)**，已分配块比有效载荷大时发生（例如，最小块大小限制、对齐要求），就是已分配块的大小和它们的有效载荷大小之差的和，因此，在任意时刻，内部碎片的数量只取决于一起按请求的模式和分配器的实现方式 -- **块内部被浪费的空间**；
 - **外部碎片(internal fragmentation)**，是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的、足够大的空闲块能来处理这个请求发生的，不仅取决于以前请求的模式和分配器的实现方式，还取决于 **将来** 请求的模式 -- **内存被切碎了**；

因为 内部碎片：可测量、可估计、可控制，外部碎片：无法精确量化、无法预测、无法彻底消除，且 `malloc` 不能移动已分配块，为此
> 分配器通常采用启发式策略来试图维持少量的大空闲块，而不是大量的小空闲块。

## 9.9.5 实现问题
可以想象出的最简单的分配器会把堆组织成一个大的字节数组，还有一个指针 `p`，初始指向这个数组的第一个字节。为了分配 `size` 个字节，`malloc` 将 `p` 的当前值保存在栈里，将 `p` 增加 `size`，并将 `p` 的旧值返回到调用函数。`free` 只是简单地返回到调用函数，而不做其他任何事情。

这个简单的分配器是设计中的一种极端情况。因为每个 `malloc` 和 `free` 只执行很少量的指令，吞吐率会极好。然而，因为分配器从不重复使用任何块，内存利用率将极差。一个实际的分配器要在吞吐率和利用率之间把握好平衡，就必须考虑以下几个问题：
* **空闲块组织**：如何记录空闲块？
* **放置**：如何选择一个合适的空闲块来放置一个新分配的块？
* **分割**：在将一个新分配的块放置到某个空闲块之后，如何处理这个空闲块中的剩余部分？
* **合并**：如何处理一个刚刚被释放的块？

本节剩下的部分将更详细地讨论这些问题。因为像放置、分割以及合并这样的基本技术贯穿在许多不同的空闲块组织中，所以将在一种叫做隐式空闲链表的简单空闲块组织结构中来介绍它们。

## 9.9.6 隐式空闲链表
任何分配器都需要一些数据结构来 **区别块边界**，以及 **区别已分配块和空闲块**。

大部分分配器将这些信息嵌入块本身，一个简单的方法如图 9-35 所示：
![[NoteAboutStudy/attachments/Pasted image 20260214203607.png]]
在这种情况下，一个块是由一个字是 **头部**、**有效载荷**，以及可选的一些额外的 **填充** 组成的：
 - 头部包含了这个块的大小（包括头部和所有的填充），以及这个块是已分配的还是空闲的；
	 - 如果强加一个双字的对其约束条件，那么所有块都是 8 的倍数，而 8 的倍数的二进制最后 3 位永远为 0，所以可以用这 3 位去编码其他信息，于是拿来存状态位。
 - 头部后是应用调用 `malloc` 时请求的有效载荷；
 - 有效载荷后是一片不使用的填充块，其大小可以是任意的（使用其可能是分配器策略的一部分，用来对付外部碎片，或者是用它来满足对其要求）；

假设块的格式如图 9-35 所示，可以将堆组织为一个连续的已分配块和空闲块的序列，如图 9-36 所示：
![[NoteAboutStudy/attachments/Pasted image 20260214204530.png]]
称这种结构为 **隐式空闲链表** -- 空闲块通过头部中的大小字段把下一个块算出来，分配器可以通过遍历堆中所有的块，从而间接地遍历整个空闲块的集合。需要一个具有某种特殊标记的结束块使遍历逻辑终止（在这个示例中，通过设置已分配位而大小为零的终止头部，同时设置已分配位也简化了空闲块的合并）。

**优点：**
- 实现极其简单
- 没有额外指针开销
**致命缺点：**
- **任何 malloc 都是 O(n)**  ，必须扫描整个堆
- 已分配块越多 → 越慢
- 吞吐率很差

> 最小块大小不是 “用户请求决定的”，而是由对齐和块格式强制决定的。

## 9.9.7 放置已分配的块
当一个应用请求一个 $k$ 字节的块时，分配器搜索空闲链表，查找一个足够大的可以放置所请求块的空闲块。分配器执行这种搜索的方式是由 **放置策略(placement policy)** 确定的，一些常见的策略是：
 - **首次适配(first fit)**，从头开始搜索空闲链表，选择第一个合适的空闲块；
	 - 优点 -- 趋向于将大的空闲块保留在链表的后面；
	 - 缺点 -- 趋向于在靠近链表起始处留下小空闲块（碎片），增加了对较大块的搜索事件；
 - **下一次适配(next fit)**， 从上一次查询结束的地方开始；
 - **最佳适配(best fit)**，检查每个空闲块，选择适合所需请求大小的最小空闲块；
	 - 在隐式空闲链表中，这种策略要求对堆进行彻底的搜索（分离式空闲链表组织最接近于最佳适配策略）；
下一次适配比首次适配运行起来要快一些，但是内存利用率比首次适配低得多。最佳适配比前两者的内存利用率都要高一些。

## 9.9.8 分割空闲块
当分配器找到了一个可以用来分配的空闲块，那么它有两个选择
 - 直接用整个空闲块，这种方式简单快捷，但是会造成内部碎片（如果放置策略趋向于产生好的匹配，额外的内部碎片也是可以接受的）；
 - 分割空闲块使用其中一部分，第一部分变成已分配块，剩下的成为一个新的空闲块，如图 9 -37 展示了分配器如何分割：
	 - ![[NoteAboutStudy/attachments/Pasted image 20260216182212.png]]
	 - 第一步：把原空闲块改写成 “已分配块”，修改 header：size = 请求大小，alloc = 1；
	 - 第二步：在剩余空间位置创建一个新块，写入新的 header（和可能的 footer），size = 剩余大小，alloc = 0，把它插回空闲链表；

## 9.9.9 获取额外的堆内存
当分配器找不到合适的空闲块时：
 1. 第一选择是合并那些在内存中物理上相邻的空闲块来创建一些更大的空闲块（将在 9.9.10 中描述）
 2. 如果此时还是没有合适的，分配器就会通过调用 `sbrk` 函数来向内核请求额外的堆内存，然后将申请到的额外的内存转化为一个大空闲块并插入到空闲链表中，最后将被请求的块放置在这个新的空闲块中；

## 9.9.10 合并空闲块
当分配器释放一个已分配块时，可能会有其他的空闲块与这个新释放的空闲块相邻，就会导致 **假碎片** 的现象 -- 有许多可连续的空闲块被切割成细碎的、无法被使用的空闲块。

因此，任何实际的分配器都必须合并相邻的空闲块 -- 这个过程称为 **合并(coalescing)**。何时执行合并：
 - **立即合并(immediate coalescing)**，在每次一个块被释放时，就检查并合并邻接的空闲块
	 - 优点：实现简单、常数时间内执行完成（看前后的块的状态即可）、堆始终保持 “尽可能大块”；
	 - 问题：可能产生抖动，块会反复合并和分割；
 - **推迟合并(deferred coalescing)**，等到 “真正需要” 的时候再统一合并（比如 9.9.9 节的那种情况）
	 - 优点：避免反复分割/合并抖动、提升吞吐量、现代高性能 `malloc` 更偏爱这种策略；
	 - 缺点：实现复杂、需要维护额外状态、某些时刻需要扫描整个堆（代价大但不频繁）；

> 快速的分配器通常会选择某种形式的推迟合并

## 9.9.11 带边界标记的合并
称想要释放的块为当前块，合并内存中的下一个空闲块，只需通过 当前块的头部（指向下一个块的头部），检查这个指针即可判断下一个块是否空闲。如果是，就将下一个块的大小加到当前块头部的大小上，就能在常数时间内合并这两个空闲块。

而对于当前块的前一个块，如果是只带头部的隐式空闲链表就需要搜索整个链表，记住前面的块的位置直到遍历到当前块，就会导致每次调用 `free` 需要的时间都与堆的大小成线性关系。

为此提出了一种称为 **边界标记(boundary tag)** 的技术，使得可以在常数时间内进行堆前一个块的合并，如图 9-39 所示：
![[NoteAboutStudy/attachments/Pasted image 20260216191154.png]]
通过在每个块的结尾处添加一个 **脚部(footer，边界标记)**，是头部的一个副本。这样分配器就可以通过检查脚部来判断前一个块的起始位置和状态（脚部就距离当前块开始位置一个字）。

当分配器释放当前块时所有可能存在的情况：
 1. 前面的块和后面的块都是已分配的；
 2. 前面已分配，后面空闲；
 3. 前面空闲，后面已分配；
 4. 前面和后面都是空闲的；
 如图 9-40 展示了如何对这四种情况进行合并：
 ![[NoteAboutStudy/attachments/Pasted image 20260216191742.png]]
 * 在情况 1 中，两个邻接的块都是已分配的，因此不可能进行合并。所以当前块的状态只是简单地从已分配变成空闲；
 * 在情况 2 中，当前块与后面的块合并。用当前块和后面块的大小的和来更新当前块的头部和后面块的脚部；
 * 在情况 3 中，前面的块和当前块合并。用两个块大小的和来更新前面块的头部和当前块的脚部；
 * 在情况 4 中，要合并所有的三个块形成一个单独的空闲块，用三个块大小的和来更新前面块的头部和后面块的脚部；
 * 在每种情况中，合并都是在常数时间内完成的；

边界标记对于许多不同类型的分配器和空闲链表组织都是通用的，但是因为它要求每个块都保持一个头部和一个脚部，在应用程序操作许多个小块时，就会产生显著的内存开销。

但是，当试图在内存中合并当前块以及前面的块和后面的块时，只有在前面的块是空闲时才会需要用到它的脚部。为此，可以把**前面块的 已分配/空闲的状态 存放在当前块多出来的低位中**（那 3 个低位），这样已分配的块就不需要脚部了，但是空闲块仍然保留脚部。

## 9.9.12 综合：实现一个简单的分配器
本节将基于隐式空闲链表，使用立即边界标记合并方式，讲述一个简单分配的实现（最大的块大小为 $2^{32}=4GB$）。

### 1. 通用分配器设计
使用如图 9-41 所示的 `memlib.c` 包所提供的内存系统模型，其目的在于允许在不干涉已存在的系统层 `malloc` 包的情况下，运行分配器：
![[NoteAboutStudy/attachments/Pasted image 20260216193405.png]]
`mem_init` 函数将对于堆来说可用的虚拟内存模型化为一个大的、双字对齐的字节数组:
 - 在 `mem_heap` 和 `mem_brk` 之间的字节表示已分配的虚拟内存；
 - `mem_brk` 之后的字节表示未分配的虚拟内存。
 - 分配器通过调用 `mem_sbrk` 函数来请求额外的堆内存，这个函数和系统的 `sbrk` 函数的接口相同，而且语义也相同，除了它会拒绝收缩堆的请求。 
 分配器包含在一个源文件中（`mm.c`），用户可以编译和链接这个源文件到他们的应用之中。分配器输出三个函数到应用程序：
```c
extern int mm_init(void);
extern void *mm_malloc (size_t size);
extern void mm_free (void *ptr);
```
 - `mm_init` 函数初始化分配器，如果成功就返回 0，否则就返回 -1；
 - `mm_malloc` 和 `mm_free` 函数 与它们对应的系统函数有相同的接口和语义。
分配器使用如图 9-39 所示的块格式。最小块的大小为 16 字节。
空闲链表组织成为一个隐式空闲链表，具有如图 9-42 所示的恒定形式。
![[NoteAboutStudy/attachments/Pasted image 20260216194521.png]]

### 2. 操作空闲链表的基本常数和宏
图 9-43 展示了一些在分配器编码中将要使用的基本常数和宏：
![[NoteAboutStudy/attachments/Pasted image 20260216194655.png]]
 - 第 2 ~ 4 行定义了一些基本的大小常数：字的大小（WSIZE）和双字的大小（DSIZE），初始空闲块的大小和扩展堆时的默认大小（CHUNKSIZE）；
 - PACK 宏（第 9 行）将大小和已分配位结合起来并返回一个值，可以把它存放在头部或者脚部中；
 - GET 宏（第 12 行）读取和返回参数 `p` 引用的字 (这里强制类型转换是至关重要的)。参数 P 是一个 (`viod*`) 指针，不可以直接进行间接引用；
 - PUT 宏（第 13 行）将 `val` 存放在参数 `p` 指向的字中；
 - GET\_SIZE 和 GET\_ALLOC 宏（第 16 \~ 17 行）从地址 `p` 处的头部或者脚部分别返回块大小和表明是否分配的位；
 - 剩下的宏是对 **块指针**（block pointer，用 bp 表示）的操作，块指针指向第一个有效载荷字节
	 - 给定一个块指针 bp，HDRP 和 FTRP 宏（第 20 ~ 21 行）分别返回指向这个块的头部和脚部的指针；
	 - NEXT\_BLKP 和 PREV\_BLKP 宏（第 24 ~ 25 行）分别返回指向后面的块和前面的块的块指针；

### 3. 创建初始空闲链表
在调用 `mm_malloc` 或者 `mm_free` 之前，必须先调用 `mm_init` 来初始化堆（如图 9- 44所示）
 ![[NoteAboutStudy/attachments/Pasted image 20260216195632.png]]
`mm_init` 函数从内存系统得到 4 个字，并将它们初始化，创建一个空的空闲链表（第 4 ~ 10 行）。然后它调用 `extend_heap` 函数（图 9-45），这个函数将堆扩展 CHUNKSIZE 字节，并且创建初始的空闲块。
 ![[NoteAboutStudy/attachments/Pasted image 20260216195847.png]]
`extend_heap` 函数会在两种不同的环境中被调用：
 - 当堆被初始化时；
 - 当 `mm_malloc` 不能找到一个合适的匹配块时。为了保持对齐，`extend_heap` 将请求大小向上舍入为最接近的 2 字（8 字节）的倍数，然后向内存系统请求额外的堆空间（第 7 ~ 9 行）；
 `extend_heap` 函数的剩余部分（第 12 ~ 17 行）则是具体如何扩展连接 -- 把旧的结尾块改造成新空闲块的头，再在最末尾补一个新的结尾块（如果旧的结尾块的前一个块是空闲块则需与改造后的新空闲块合并 - 通过 `coalesce` 函数）。

此刻，分配器已初始化了，并且准备好接受来自应用的分配和释放请求。

### 4. 释放和合并块
通过调用 `mm_free` 函数（如图 9-46 所示），来释放一个以前分配的块，这个函数释放所请求的块(bp)，然后使用 9.9.11 节所描述的边界标记合并来将其与邻接的空闲块合并起来。
![[NoteAboutStudy/attachments/Pasted image 20260216200528.png]]
`coalesce` 函数是四种合并情况的一种简单直接的实现（选择的空闲链表格式 -- 它的序言块和结尾块总是标记为已分配，允许忽略潜在的麻烦边界情况，也就是，请求块 bp 在堆的起始处或者是在堆的结尾处，这样就不用去检查并不常见的边界情况）。

### 5. 分配块
当通过调用 `mm_malloc` 函数（如图 9-47 所示）来向内存请求大小为 `size` 字节的块。
![[NoteAboutStudy/attachments/Pasted image 20260216202109.png]]
 - 在检査完请求的真假之后，分配器必须调整请求块的大小，从而为头部和脚部留有空间，并满足双字对齐的要求；
 - 第 12 ~ 13 行强制了最小块大小是 16 字节：8 字节用来满足对齐要求，而另外 8 个用来放头部和脚部。对于超过 8 字节的请求（第 15 行），一般的规则是加上开销字节，然后向上舍入到最接近的 8 的整数倍。
 - 一旦分配器调整了请求的大小，它就会搜索空闲链表，寻找一个合适的空闲块（第 18 行）。如果有合适的，那么分配器就放置这个请求块，并可选地分割出多余的部分（第 19 行），然后返回新分配块的地址；
 - 一旦分配器调整了请求的大小，它就会搜索空闲链表，寻找一个合适的空闲块（第 18 行）。如果有合适的，那么分配器就放置这个请求块，并可选地分割出多余的部分（第 19 行），然后返回新分配块的地址；

## 9.9.13 显式空闲链表
将空闲块组织为某种形式的显式数据结构，根据定义，程序不需要空闲块的主体，所以可以将实现这个数据结构的指针放在空闲块自己的主体里。例如，堆可以组织成一个双向空闲链表，在每个空闲块中，都包含一个 `pred`(前驱) 和 `succ`(后继) 指针，如图 9-48 所示：
![[NoteAboutStudy/attachments/Pasted image 20260216203951.png]]
使用双向链表，使首次适配的分配时间从 **块总数** 的线性时间减少为 **空闲块** 数量的线性时间。释放一个块的时间可以是线性的，也可能是个常数，取决于选择的空闲链表中块的排序策略：
 - **后进先出(LIFO)** 的顺序维护链表，新释放的块放置在链表的开始处。
	 - 这样分配器会最先检查最近使用过的块，就可以在常数时间内完成释放；
	 - 如果使用了边界标记，合并也可以在常数时间内完成；
- **地址顺序** 维护链表，链表中每个块的地址都小于它后继的地址。
	- 释放一个块需要线性时间的搜索来定位合适的前驱；
	- 但是首次适配比 LIFO 的首次适配有更高的内存利用率（接近最佳适配的利用率）；

一般而言，显式链表的缺点是空闲块必须足够大，以包含所有需要的指针，以及头部和可能的脚部。这就导致了更大的最小块大小，也潜在地提高了内部碎片的程度。

## 9.9.14 分离的空闲链表
为了减少分配时间，维护多个空闲链表，其中每个链表中的块有大致相等的大小，这种方法称为 **分离存储(segregated storage)**。一般的思路是将所有可能的块大小分为一些等价类，也叫做 **大小类(size class)** - 像 “桶”。分配器维护一个空闲链表的数组，每个大小类一个空闲链表，按照大小的升序排列。当分配器需要一个块时，就搜索相应的空闲链表，如果在其中不能找到合适的块就搜索下一个链表。

不同的分离存储方法，主要的区别在于如何定义大小类、何时合并、何时向操作系统请求额外的堆内存、是否允许分割等等，以下将会讲述两种基本方法：

---
### 1. 简单分离存储(simple segregated storage)
每个大小类的空闲链表包含大小相等的块，每个块的大小就是这个大小类中最大元素的大小。

- 当分配一个给定大小的块，检查相应的空闲链表：
	- 如果链表内还有未使用的块，直接分配其中第一块的全部，空闲块并不会分割以满足分配请求；
	- 如果链表内没有未使用的块，分配器就向操作系统请求一个固定带下的额外内存片，将这个片分成大小相等的块（当前链表中的块的大小），并将这些块链接起来；
- 当释放一个块，分配器只需将这个块插到相应的空闲链表的前部；

特点总结：
 - 分配 O(1)  
 - 释放 O(1)  
 - 无分割  
 - 无合并  
 - 无 header  
 - 无 footer  
 - 链表可以单向

缺点：内部碎片（空闲块不分割）和外部碎片（不合并）很严重

### 2. 分离适配(segregated fit)
分配器维护着一个空闲链表的数组，每个空闲链表是和一个大小类相关联的，并且被组织成某种类型的显式或隐式链表，**每个链表包含潜在的大小不同的块**，这些块的大小是大小类的成员。

- 当分配一个块时，必须确定请求的大小类，并且堆适当的空闲链表做首次适配，查找一个合适的块：
	- 如果找到了，就（可选地）分割它，并将剩余部分插入到适当的空闲链表中；
	- 如果没找到，就搜索下一个更大的大小类的空闲链表，如此重复，直到找到；
	- 如果空闲链表中没有合适的块，就向操作系统请求额外的堆内存，从这个新的堆内存中分配出一个块，将剩余部分放置在适当的大小类中；
- 当释放一个块时，执行合并，并将结构放置到相应的空闲链表中；

分离适配方法是一种常见的选择，C 标准库中提供的 GNU malloc 包就是釆用的这种方法，因为这种方法既快速，对内存的使用也很有效率：
 - 搜索时间减少了，因为搜索被限制在堆的某个部分，而不是整个堆；
 - 内存利用率得到了改善，因为对分离空闲链表的简单的首次适配搜索，其内存利用率近似于对整个堆的最佳适配搜索的内存利用率；

### 3. 伙伴系统
**伙伴系统(buddy system)** 是分离适配的一种特例，其中每个大小类都是 2 的幂。假设一个堆的大小为 $2^m$ 个字，为每个块大小 $2^k$ 维护一个分离空闲链表，其中 $0\leqslant k \leqslant m$。请求块大小向上舍入到最接近的 2 的幂。最开始时，只有一个大小为 $2^m$ 个字的空闲块。

 - 为了分配一个大小为 $2^k$ 的块，找到第一个可用的、大小为 $2^j$ 的块，其中 $k\leqslant j \leqslant m$：
	 - 如果 $j=k$，那么就完成了；
	 - 否则，递归地二分割这个块，直到当进行这样的分割时，每个剩下的半块（也叫做伙伴）被放置在相应的空闲链表中；
- 当释放一个大小为 $2^k$ 的块，递归向上合并空闲的伙伴，直到遇到一个已分配的伙伴；

> 伙伴地址 = 地址 XOR 块大小

优点：快速搜索、快速合并；
缺点：内部碎片显著；
适用范围：不适合通用 `malloc`，当对于特定的、块大小预先知道是 2 的幂，就比较适合。

# 9.10 垃圾收集
由于在 C `malloc` 包这样的显式分配器中，应用通过调用 `malloc` 和 `free` 来分配和释放堆块，如果在不需要后没有释放堆块，就会一直在程序的生命周期内保持为已分配状态，占用本来可以用来满足后面分配请求的堆空间。

**垃圾收集器(garbage collector)** 是一种动态内存分配器，自动释放程序不再需要的已分配块，即应用只负责 `malloc`，不再调用 `free`；系统会自动识别哪些已经不再被程序使用，并替程序调用 `free` 把它们回收。这些块被称为 **垃圾**，自动回收的过程称为 **垃圾收集**。 

本节介绍 `Mark & Sweep`（标记-清除）。它的重要意义在于：可以构建在现有 `malloc` 之上，为 C/C++ 提供自动回收能力。

---
## 9.10.1 垃圾收集器的基本知识
垃圾收集器将内存视为一张有向**可达图(reachability graph)**，其形式如图 9-49 所示：![[NoteAboutStudy/attachments/Pasted image 20260217194315.png]]
图里有两类节点：
 - 一类叫根节点（roots），它们不在堆里，是程序运行时天然存在、始终可访问的 “起点”，包括：寄存器里的指针、栈上的局部变量、全局变量区里的指针（可以把它们理解为程序随时能直接拿到的指针来源）
 - 一类叫堆节点（heap nodes），每一个已经分配的堆块（每个 `malloc` 出来的对象）。如果块 `p` 的内部某个字段存着一个指针指向块 `q`，就在图里画一条边 `p → q`。

当存在一条从任意根节点出发并到达 `p` 的有向路径时，称 `p` 节点是 **可达的**，反之没有任意一天路径可以从根节点到 `p` 节点，则称 `p` 节点不可达的（垃圾）。

> 垃圾收集器的工作就是：维护这张可达图，并将不可达节点释放并返回给空闲链表。

像 Java、ML 这种语言，对指针是严格控制的：变量是不是指针、指向哪里，运行时完全知道。  因此它们可以维护精确的可达图，垃圾一定能全部回收；但 C/C++ 不行，因为在 C 里，任何整数都可能被当作地址，垃圾收集器无法判断一个值到底是不是指针，于是采取保守策略，宁愿把不可达的块标记为可达，也不能误删。

收集器可以按需提供服务，或者将它们作为一个和应用并行的独立线程，不断更新可达图和回收垃圾：
 1. 当程序调用 `malloc`，先按正常分配器流程找空闲块;
 2. 如果找不到，`malloc` 会暂停 → 调用垃圾收集器；
 3. 垃圾处理器扫描内存，找出垃圾块，然后 **替程序调用 free**；
 4. 垃圾处理器结束后，`malloc` 再尝试一次分配。如果仍然失败，才向操作系统申请更多堆内存（`sbrk` 函数）；

## 9.10.2 `Mark & Sweep` 垃圾收集器
`Mark & Sweep` 垃圾收集器由 **标记(mark)** 阶段和 **清楚(sweep)** 阶段组成，标记阶段标记出根节点的所有可达的块，而后面的清除阶段释放每个未被标记的已分配的块（块头部中空闲的低 3 位中的一位通常来表示这个块是否被标记了）。

标记阶段为每个根节点调用一次 如图 9-51a 所示的 `mark` 函数：
 - 如果 `p` 不指向一个已分配并且未标记的堆块，`mark` 函数就立即返回；
 - 否则，它就标记这个块，扫描块内部的所有字 -- 即把**对象内部所有内容都当作可能的指针**再递归扫描，每次对 `mark` 函数的调用读标记某个根节点的所有未标记的可达的堆块，最后剩下的就是 **垃圾**；
清洗阶段是通过调用一次 如图 9-51b 所示的 `sweep` 函数，对堆中每个块反复循环 -- 顺序扫描堆，释放所遇到的所有未标记的已分配块。
![[NoteAboutStudy/attachments/Pasted image 20260217203534.png]]

## 9.10.3 C 程序的保守 `Mark & Sweep`
`Mark & Sweep` 对 C 程序的垃圾收集是一种合适的方法，因为它可以原地执行，不需要移动块，但是 C 语言对于判断 “所给的值” 是否指向某个堆块略有困难。

其一，C 不会用任何类型信息来标记内存位置，因此没有一种明显的方式来判断输入参数是不是一个指针。
其二，即使知道是一个指针了，也没有一种明显的方式来判断是否指向一个已分配块的有效载荷中的某个位置（标记在头部中）。

为此解决方法是将已分配块的集合维护成一棵按地址排序的平衡二叉树，树中每个节点 = 一个已分配块的头部，左子树 → 地址更小，右子树 → 地址更大，这使得可以对地址做 **二分查找**。

在平衡树中查找，找到地址最接近 `p` 的块 `b`，然后检查：`block_start(b) ≤ p < block_end(b)`，这里就用到了 **块头部中的 size 字段**，就能算出：`block_end = block_start + size`，如果 `p` 落在这个区间里 →  就认为 `p` 指向该块（哪怕是指向有效载荷）。这样只要存在指针指向某个块的地址范围就能找到这个块。

但是对于不知道所给的值是否是指针的情况只能认为它是指针，从而保证不会误释放对象，影响程序运行，这就是所谓保守。

# 9.11 C 程序中常见的与内存有关的错误
---
## 9.11.1 间接引用坏指针
> 程序把 “不是地址的值” 当成地址去进行读写。

进程的虚拟地址空间并不是连续都可用的。里面有三类区域：  
 1. 根本没有映射的 “洞”（holes）  
 2. 只读区域（代码段、只读常量）  
 3. 可读写区域（堆、栈、数据段）
当程序通过指针访问内存时，CPU + OS 会检查：
 - 这个地址是否存在映射
 - 是否允许读/写
若不满足，就触发异常：
 - 访问空洞 → 段错误（segmentation fault）
 - 写只读区 → 保护错误（protection fault）
但是，如果错误的内容（比如说是数据之类的）被解释为一个可以读写的地址，就会覆盖这个区域，导致不应该执行的区域被修改了，就会导致未来的某个时刻在完全无关的地方崩溃。

## 9.11.2 读未初始化的内存
虽然 `bss` 内存位置（诸如未初始化的全局 C 变量）总是被加载器初始化为零，但是对于堆内存却并不会初始化。一个常见的错误就是以为堆内存被初始化为零了：

```c
/* Return y = Ax */
int *matvec(int **A, int *x, int n)
{
    int i, j;
    
    int *y = (int *)Malloc(n * sizeof(int));
    
    for (i = 0; i < n; i++)
        for (j = 0; j < n; j++)
            y[i] += A[i][j] * x[j];
    return y;
}
```

在这个示例中，程序员不正确地假设向量 `y` 被初始化为零。正确的实现方式是显式地将 `y[i]` 设置为零，或者使用 `calloc`。

## 9.11.3 允许栈缓冲区溢出
如果一个程序不检查输入串的大小就写入栈中的目标缓冲区，就会有 **缓冲区溢出错误(buffer overflow bug)**，为防止错误，可以限制输入串的大小。

## 9.11.4 假设指针和所指向的对象是相同大小的

## 9.11.5 造成错位错误

## 9.11.6 引用指针，而不是它所指向的对象

## 9.11.7 误解指针运算

## 9.11.8 引用不存在的变量

## 9.11.9 引用空闲堆块中的数据

## 9.11.10 引起内存泄漏

# 9.12 小结